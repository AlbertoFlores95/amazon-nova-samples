{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279ef729",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf22f0",
   "metadata": {},
   "source": [
    "Before you can use Amazon Bedrock, you must carry out the following steps:\n",
    "\n",
    "* Sign up for an AWS account (if you don't already have one) and IAM Role with the necessary permissions for Amazon Bedrock, see AWS Account and IAM Role.\n",
    "\n",
    "* Request access to the foundation models (FM) that you want to use, see Request access to FMs.\n",
    "\n",
    "\n",
    "In this Notebook you will use the following Foundation Models in us-east-1 (N. Virginia) region:\n",
    "\n",
    "| Provider Name | Foundation Model Name | Model Id |\n",
    "| ------------- | --------------------- | ------------- |\n",
    "| Amazon        | Nova Pro              | us.amazon.nova-pro-v1:0 |\n",
    "| Mistral       | Mistral Large         | mistral.mistral-large-2402-v1:0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfde93e-e92c-4f38-9827-8a3f213d4bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from IPython.display import JSON, display, IFrame, Markdown\n",
    "import os\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import sagemaker\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "# Set up AWS credentials (make sure you have the appropriate permissions)\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bedrock_client = session.client('bedrock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6c6d7f-1aa3-4810-99a4-fc1e08532056",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_model = \"mistral.mistral-large-2402-v1:0\"\n",
    "generator_model = \"us.amazon.nova-pro-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2947f29f-1c8b-4069-9bdc-33a3c6115621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(local_file: str, bucket: str, s3_key: str) -> bool:\n",
    "    \"\"\"\n",
    "    Upload a file to S3 with error handling.\n",
    "    \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3_client = session.client('s3')\n",
    "        s3_client.upload_file(local_file, bucket, s3_key)\n",
    "        print(f\"✓ Successfully uploaded {s3_key}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error uploading to S3: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600c4696-8554-41d4-9a7a-95e1a9597bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "def create_llm_judge_evaluation(\n",
    "    client,\n",
    "    job_name: str,\n",
    "    role_arn: str,\n",
    "    input_s3_uri: str,\n",
    "    output_s3_uri: str,\n",
    "    evaluator_model_id: str,\n",
    "    generator_model_id: str,\n",
    "    dataset_name: str = None,\n",
    "    task_type: str = \"General\" # must be General for LLMaaJ\n",
    "):    \n",
    "    # All available LLM-as-judge metrics\n",
    "    llm_judge_metrics = [\n",
    "        \"Builtin.Correctness\",\n",
    "        \"Builtin.Completeness\", \n",
    "        \"Builtin.Faithfulness\",\n",
    "        \"Builtin.Helpfulness\",\n",
    "        \"Builtin.Coherence\",\n",
    "        \"Builtin.Relevance\",\n",
    "        \"Builtin.FollowingInstructions\",\n",
    "        \"Builtin.ProfessionalStyleAndTone\",\n",
    "        \"Builtin.Harmfulness\",\n",
    "        \"Builtin.Stereotyping\",\n",
    "        \"Builtin.Refusal\"\n",
    "    ]\n",
    "\n",
    "    # Configure dataset\n",
    "    dataset_config = {\n",
    "        \"name\": dataset_name or \"CustomDataset\",\n",
    "        \"datasetLocation\": {\n",
    "            \"s3Uri\": input_s3_uri\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = client.create_evaluation_job(\n",
    "            jobName=job_name,\n",
    "            roleArn=role_arn,\n",
    "            applicationType=\"ModelEvaluation\",\n",
    "            evaluationConfig={\n",
    "                \"automated\": {\n",
    "                    \"datasetMetricConfigs\": [\n",
    "                        {\n",
    "                            \"taskType\": task_type,\n",
    "                            \"dataset\": dataset_config,\n",
    "                            \"metricNames\": llm_judge_metrics\n",
    "                        }\n",
    "                    ],\n",
    "                    \"evaluatorModelConfig\": {\n",
    "                        \"bedrockEvaluatorModels\": [\n",
    "                            {\n",
    "                                \"modelIdentifier\": evaluator_model_id\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            inferenceConfig={\n",
    "                \"models\": [\n",
    "                    {\n",
    "                        \"bedrockModel\": {\n",
    "                            \"modelIdentifier\": generator_model_id\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            outputDataConfig={\n",
    "                \"s3Uri\": output_s3_uri\n",
    "            }\n",
    "        )\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating evaluation job: {str(e)}\")\n",
    "        raise\n",
    "        \n",
    "\n",
    "\n",
    "def run_model_comparison(sagemaker_session_role: str,\n",
    "    generator_models: List[str],\n",
    "    evaluator_model: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    evaluation_jobs = []\n",
    "    \n",
    "    for generator_model in generator_models:\n",
    "        job_name = f\"llmaaj-{generator_model.split('.')[0]}-{evaluator_model.split('.')[0]}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "        \n",
    "        try:\n",
    "            response = create_llm_judge_evaluation(\n",
    "                client=bedrock_client,\n",
    "                job_name=job_name,\n",
    "                role_arn=sagemaker_session_role,\n",
    "                input_s3_uri=input_data,\n",
    "                output_s3_uri=f\"{output_path}/{job_name}/\",\n",
    "                evaluator_model_id=evaluator_model,\n",
    "                generator_model_id=generator_model,\n",
    "                task_type=\"General\"\n",
    "            )\n",
    "            \n",
    "            job_info = {\n",
    "                \"job_name\": job_name,\n",
    "                \"job_arn\": response[\"jobArn\"],\n",
    "                \"generator_model\": generator_model,\n",
    "                \"evaluator_model\": evaluator_model,\n",
    "                \"status\": \"CREATED\"\n",
    "            }\n",
    "            evaluation_jobs.append(job_info)\n",
    "            \n",
    "            print(f\"✓ Created job: {job_name}\")\n",
    "            print(f\"  Generator: {generator_model}\")\n",
    "            print(f\"  Evaluator: {evaluator_model}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with {generator_model}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return evaluation_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126ed92d-7816-4a8a-bace-a948611353a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bucket already exists\n",
      "✓ Successfully uploaded evaluation_output/eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "OUTPUT_DIR = \"evaluation_output\"\n",
    "INPUT_DATASET = \"eval_dataset.jsonl\"\n",
    "DATA_BUCKET = f\"nova-citations-{account_id}\"\n",
    "s3_key = f\"{OUTPUT_DIR}/{INPUT_DATASET}\"\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "try:\n",
    "    s3_client = session.client('s3')\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=DATA_BUCKET,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region_name} if region_name != 'us-east-1' else {}\n",
    "    )\n",
    "    print(f\"✓ Created bucket {DATA_BUCKET}\")\n",
    "except Exception as e:\n",
    "    if 'BucketAlreadyOwnedByYou' in str(e):\n",
    "        print(f\"✓ Bucket already exists\")\n",
    "    else:\n",
    "        print(f\"✗ Error creating bucket: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Upload the dataset\n",
    "upload_success = upload_to_s3(INPUT_DATASET, DATA_BUCKET, s3_key)\n",
    "if not upload_success:\n",
    "    raise Exception(\"✗ Failed to upload dataset to S3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b42fdb-01c2-4dc3-9281-060a0396f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import re\n",
    "# Get the execution role\n",
    "sagemaker_session_role = sagemaker.get_execution_role()\n",
    "# Create evaluation job\n",
    "input_data = f\"s3://{DATA_BUCKET}/{s3_key}\"\n",
    "output_path = f\"s3://{DATA_BUCKET}/{OUTPUT_DIR}\"\n",
    "print(\"input_data\",input_data)\n",
    "print(\"output_path\",output_path)\n",
    "try:\n",
    "    unique_job_sux = str(uuid.uuid4())[:16]  \n",
    "    llm_as_judge_response = create_llm_judge_evaluation(\n",
    "        client=bedrock_client,\n",
    "        job_name=f\"evalnovacitations-{unique_job_sux}\",\n",
    "        role_arn=sagemaker_session_role,\n",
    "        input_s3_uri=input_data,\n",
    "        output_s3_uri=output_path,\n",
    "        evaluator_model_id=evaluator_model,\n",
    "        generator_model_id=generator_model,\n",
    "        task_type=\"General\"\n",
    "    )\n",
    "    print(f\"✓ Created evaluation job: {llm_as_judge_response['jobArn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to create evaluation job: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Get job ARN based on job type\n",
    "evaluation_job_arn = llm_as_judge_response['jobArn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6399ff9c-e5f9-4350-893d-9d0480496cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: InProgress\n"
     ]
    }
   ],
   "source": [
    "# Check job status\n",
    "check_status = bedrock_client.get_evaluation_job(jobIdentifier=evaluation_job_arn) \n",
    "print(f\"Job Status: {check_status['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060ef67-d0a5-4815-b5fe-b6118716fddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
