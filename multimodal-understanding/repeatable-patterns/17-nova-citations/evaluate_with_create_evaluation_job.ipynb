{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcfde93e-e92c-4f38-9827-8a3f213d4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from IPython.display import JSON, display, IFrame, Markdown\n",
    "import os\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import sagemaker\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "# Set up AWS credentials (make sure you have the appropriate permissions)\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bedrock_client = session.client('bedrock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b6c6d7f-1aa3-4810-99a4-fc1e08532056",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_model = \"mistral.mistral-large-2402-v1:0\"\n",
    "generator_model = \"us.amazon.nova-pro-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2947f29f-1c8b-4069-9bdc-33a3c6115621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(local_file: str, bucket: str, s3_key: str) -> bool:\n",
    "    \"\"\"\n",
    "    Upload a file to S3 with error handling.\n",
    "    \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3_client = session.client('s3')\n",
    "        s3_client.upload_file(local_file, bucket, s3_key)\n",
    "        print(f\"✓ Successfully uploaded to s3://{bucket}/{s3_key}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error uploading to S3: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "600c4696-8554-41d4-9a7a-95e1a9597bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def create_llm_judge_evaluation(\n",
    "    client,\n",
    "    job_name: str,\n",
    "    role_arn: str,\n",
    "    input_s3_uri: str,\n",
    "    output_s3_uri: str,\n",
    "    evaluator_model_id: str,\n",
    "    generator_model_id: str,\n",
    "    dataset_name: str = None,\n",
    "    task_type: str = \"General\" # must be General for LLMaaJ\n",
    "):    \n",
    "    # All available LLM-as-judge metrics\n",
    "    llm_judge_metrics = [\n",
    "        \"Builtin.Correctness\",\n",
    "        \"Builtin.Completeness\", \n",
    "        \"Builtin.Faithfulness\",\n",
    "        \"Builtin.Helpfulness\",\n",
    "        \"Builtin.Coherence\",\n",
    "        \"Builtin.Relevance\",\n",
    "        \"Builtin.FollowingInstructions\",\n",
    "        \"Builtin.ProfessionalStyleAndTone\",\n",
    "        \"Builtin.Harmfulness\",\n",
    "        \"Builtin.Stereotyping\",\n",
    "        \"Builtin.Refusal\"\n",
    "    ]\n",
    "\n",
    "    # Configure dataset\n",
    "    dataset_config = {\n",
    "        \"name\": dataset_name or \"CustomDataset\",\n",
    "        \"datasetLocation\": {\n",
    "            \"s3Uri\": input_s3_uri\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = client.create_evaluation_job(\n",
    "            jobName=job_name,\n",
    "            roleArn=role_arn,\n",
    "            applicationType=\"ModelEvaluation\",\n",
    "            evaluationConfig={\n",
    "                \"automated\": {\n",
    "                    \"datasetMetricConfigs\": [\n",
    "                        {\n",
    "                            \"taskType\": task_type,\n",
    "                            \"dataset\": dataset_config,\n",
    "                            \"metricNames\": llm_judge_metrics\n",
    "                        }\n",
    "                    ],\n",
    "                    \"evaluatorModelConfig\": {\n",
    "                        \"bedrockEvaluatorModels\": [\n",
    "                            {\n",
    "                                \"modelIdentifier\": evaluator_model_id\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            inferenceConfig={\n",
    "                \"models\": [\n",
    "                    {\n",
    "                        \"bedrockModel\": {\n",
    "                            \"modelIdentifier\": generator_model_id\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            outputDataConfig={\n",
    "                \"s3Uri\": output_s3_uri\n",
    "            }\n",
    "        )\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating evaluation job: {str(e)}\")\n",
    "        raise\n",
    "        \n",
    "\n",
    "\n",
    "def run_model_comparison(sagemaker_session_role: str,\n",
    "    generator_models: List[str],\n",
    "    evaluator_model: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    evaluation_jobs = []\n",
    "    \n",
    "    for generator_model in generator_models:\n",
    "        job_name = f\"llmaaj-{generator_model.split('.')[0]}-{evaluator_model.split('.')[0]}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "        \n",
    "        try:\n",
    "            response = create_llm_judge_evaluation(\n",
    "                client=bedrock_client,\n",
    "                job_name=job_name,\n",
    "                role_arn=sagemaker_session_role,\n",
    "                input_s3_uri=input_data,\n",
    "                output_s3_uri=f\"{output_path}/{job_name}/\",\n",
    "                evaluator_model_id=evaluator_model,\n",
    "                generator_model_id=generator_model,\n",
    "                task_type=\"General\"\n",
    "            )\n",
    "            \n",
    "            job_info = {\n",
    "                \"job_name\": job_name,\n",
    "                \"job_arn\": response[\"jobArn\"],\n",
    "                \"generator_model\": generator_model,\n",
    "                \"evaluator_model\": evaluator_model,\n",
    "                \"status\": \"CREATED\"\n",
    "            }\n",
    "            evaluation_jobs.append(job_info)\n",
    "            \n",
    "            print(f\"✓ Created job: {job_name}\")\n",
    "            print(f\"  Generator: {generator_model}\")\n",
    "            print(f\"  Evaluator: {evaluator_model}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with {generator_model}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return evaluation_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "126ed92d-7816-4a8a-bace-a948611353a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully uploaded to s3://nova-citations/evaluation_output/eval_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"evaluation_output\"\n",
    "INPUT_DATASET = \"eval_dataset.jsonl\"\n",
    "DATA_BUCKET = \"nova-citations\"\n",
    "s3_key =f\"{OUTPUT_DIR}/{INPUT_DATASET}\"\n",
    "upload_success = upload_to_s3(INPUT_DATASET, DATA_BUCKET, s3_key)\n",
    "if not upload_success:\n",
    "    raise Exception(\"Failed to upload dataset to S3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8b42fdb-01c2-4dc3-9281-060a0396f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data s3://nova-citations/evaluation_output/eval_dataset.jsonl\n",
      "output_path s3://nova-citations/evaluation_output\n",
      "✓ Created evaluation job: arn:aws:bedrock:us-west-2:146666888814:evaluation-job/n3o6lnsb8ykn\n",
      "Job Status: InProgress\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import re\n",
    "# Get the execution role\n",
    "sagemaker_session_role = sagemaker.get_execution_role()\n",
    "# Create evaluation job\n",
    "input_data = f\"s3://{DATA_BUCKET}/{s3_key}\"\n",
    "output_path = f\"s3://{DATA_BUCKET}/{OUTPUT_DIR}\"\n",
    "print(\"input_data\",input_data)\n",
    "print(\"output_path\",output_path)\n",
    "try:\n",
    "    \n",
    "    llm_as_judge_response = create_llm_judge_evaluation(\n",
    "        client=bedrock_client,\n",
    "        job_name=\"evalnovacitations\",\n",
    "        role_arn=sagemaker_session_role,\n",
    "        input_s3_uri=input_data,\n",
    "        output_s3_uri=output_path,\n",
    "        evaluator_model_id=evaluator_model,\n",
    "        generator_model_id=generator_model,\n",
    "        task_type=\"General\"\n",
    "    )\n",
    "    print(f\"✓ Created evaluation job: {llm_as_judge_response['jobArn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to create evaluation job: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Get job ARN based on job type\n",
    "evaluation_job_arn = llm_as_judge_response['jobArn']\n",
    "# Check job status\n",
    "check_status = bedrock_client.get_evaluation_job(jobIdentifier=evaluation_job_arn) \n",
    "print(f\"Job Status: {check_status['status']}\")\n",
    "\n",
    "# Consistent Evaluator\n",
    "#EVALUATOR_MODEL = \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399ff9c-e5f9-4350-893d-9d0480496cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
