{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f661d3",
   "metadata": {},
   "source": [
    "# Amazon Nova Video FMs Batch Inference with Bedrock\n",
    "## Work with videos on a large scale\n",
    "This notebook walks through the end-to-end process of running batch inference on a collection of videos stored in S3 using Amazon Nova Pro or Premium via Bedrock.\n",
    "\n",
    "With [Batch Inference](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html), you can provide a set of prompts as a single input file and receive responses as a single output file, allowing you to get simultaneous large-scale predictions. The responses are processed and stored in your Amazon S3 bucket so you can access them at a later time. Amazon Bedrock offers support for Amazon Nova FMs for batch inference at a 50% lower price compared to on-demand inference pricing. Please refer to model list [here](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-supported.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a007b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "**Amazon Bedrock** provides a unified API for invoking foundation models like Nova Lite, Nova Pro or Nova Premier as described [here](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html). When you have a **large set of videos** you want analyzed and summarized, captioned, or classified—you can use **batch inference**. This notebook shows you how to:\n",
    "\n",
    "1. Discover all your MP4 videos in S3\n",
    "2. Build a JSONL payload referencing them\n",
    "3. Upload payload to S3\n",
    "4. Kick off a Nova batch job\n",
    "5. Poll for completion\n",
    "6. Download the results locally and explore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9654f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Prerequisites](#prerequisites)\n",
    "2. [Install Dependencies](#install-dependencies)\n",
    "3. [Configuration & Imports](#configuration--imports)\n",
    "4. [Helper Functions](#helper-functions)\n",
    "5. [List Videos in S3](#list-videos-in-s3)\n",
    "6. [Build JSONL Payload](#build-jsonl-payload)\n",
    "7. [Upload JSONL to S3](#upload-jsonl-to-s3)\n",
    "8. [Invoke Batch Job](#invoke-batch-job)\n",
    "9. [Poll Job Status](#poll-job-status)\n",
    "10. [Download Results](#download-results)\n",
    "11. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17540f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Before you begin, ensure that you have the following prerequisites in place:\n",
    "1. Updated boto3 to 1.35.1 or a greater version.\n",
    "2. You must have permissions to invoke `CreateModelInvocationJob` and `GetModelInvocationJob` API. Refer to the documentation to learn about [required permissions for batch inference job](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-prereq.html#batch-inference-permissions).\n",
    "3. Provide a S3 bucket with empty prefixes for `video/batch/input/` and `video/batch/output/`.\n",
    "4. Bedrock Batch Inference requires a service role so that it can access and write to S3 on your behalf. You can create the service role manually [see here](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-iam-sr.html) or use the AWS Console workflow which can create one for you [here](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/batch-inference/create). We also provide a quick way to create a service role in the code below. The role requires permissions to read and write data on Amazon S3 bucket (`GetObject`, `ListBucket`, `PutObject`).\n",
    "5. This notebook was built using videos `.mp4` format.\n",
    "6. Ensure that you are in a AWS region that is supported for Batch Inference. Refer [here](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference-supported.html) for documentation.\n",
    "7. The default maximum size of a single file (in GB) submitted for batch inference for Nova models is 1 GB. However, you can request an increase [here](https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas/L-68FC8D47) as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e53fe-e554-44c7-9552-7974ccaf5312",
   "metadata": {},
   "source": [
    "### Upload videos to your Amazon S3 bucket\n",
    "Upload the whole folder **academic_source** which you can find the the dataset folder to your bucket.\n",
    "In case you want to use a different folder structure in Amazon S3, you have to change the variable **VIDEOS_SOURCE_PREFIX**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8dd67c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38.3\n"
     ]
    }
   ],
   "source": [
    "import boto3 \n",
    "print(boto3.__version__) \n",
    "# if not upgrade boto3 1.35.1 or greater version, uncomment below\n",
    "# %pip install --upgrade pip\n",
    "# %pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6b4857-6f39-4f64-a6f8-efef6e628cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "import html\n",
    "import os\n",
    "import time\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from urllib.parse import urlparse\n",
    "from botocore.config import Config as BConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc8a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME          = 'batchnovabucket'\n",
    "VIDEOS_SOURCE_PREFIX = 'video/batch/source/academic_source'\n",
    "INPUT_PREFIX         = 'video/batch/input'\n",
    "OUTPUT_PREFIX        = 'video/batch/output'\n",
    "MODEL_ID             = 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0'\n",
    "ROLE_ARN             = 'ROLE_ARN'\n",
    "MAX_TOKENS           = 200\n",
    "OUTPUT_FOLDER        = 'outputs'\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize AWS clients\n",
    "boto_cfg = BConfig(retries={'max_attempts':10,'mode':'standard'})\n",
    "session = boto3.Session()\n",
    "s3 = session.client('s3', config=boto_cfg)\n",
    "bedrock = session.client('bedrock', config=boto_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2c55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import re\n",
    "import html\n",
    "def list_mp4s_in_s3(bucket, prefix):\n",
    "    \"\"\"\n",
    "    Recursively list all .mp4 object keys under a given S3 prefix.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Listing MP4s under s3://{bucket}/{prefix}/\")\n",
    "    token = None\n",
    "    keys = []\n",
    "    while True:\n",
    "        params = {'Bucket': bucket, 'Prefix': prefix}\n",
    "        if token:\n",
    "            params['ContinuationToken'] = token\n",
    "        resp = s3.list_objects_v2(**params)\n",
    "        for obj in resp.get('Contents', []):\n",
    "            k = obj['Key']\n",
    "            if k.lower().endswith('.mp4'):\n",
    "                keys.append(k)\n",
    "                logger.info(f\"  • {k}\")\n",
    "        if not resp.get('IsTruncated'):\n",
    "            break\n",
    "        token = resp.get('NextContinuationToken')\n",
    "    return keys\n",
    "\n",
    "def build_jsonl_from_s3_keys(keys, bucket):\n",
    "    \"\"\"\n",
    "    Build a list of JSONL-ready records pointing to videos via s3Location.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for idx, k in enumerate(keys):\n",
    "        uri = f\"s3://{bucket}/{k}\"\n",
    "        video_obj = {\n",
    "            'video': {'format':'mp4', 'source':{'s3Location':{'uri':uri}}}\n",
    "        }\n",
    "        text_obj = {'text':'Please summarize this video in ~200 words.'}\n",
    "        rec = {\n",
    "            'recordId': f'video-{idx}',\n",
    "            'modelInput':{\n",
    "                'schemaVersion':'messages-v1',\n",
    "                'messages':[{'role':'user','content':[text_obj, video_obj]}],\n",
    "                'inferenceConfig':{'maxTokens':MAX_TOKENS}\n",
    "            }\n",
    "        }\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "\n",
    "def pretty_llm_print(video_output, title=None):\n",
    "    \"\"\"Generates formatted output showing the prompt once and then video names and their summaries.\"\"\"\n",
    "    # Header styling\n",
    "    header = \"\"\n",
    "    if title:\n",
    "        header = f\"\"\"<div style='border: 2px solid #000000; \n",
    "            padding: 10px; \n",
    "            border-radius: 5px; \n",
    "            max-width: fit-content; \n",
    "            margin: 0 auto; \n",
    "            text-align: center; \n",
    "            font-weight: bold;'>{title}</div>\\n\"\"\"\n",
    "\n",
    "    body_parts = [header]\n",
    "    \n",
    "    # Display the prompt (user's question) ONCE at the top\n",
    "    if video_output:\n",
    "        user_content = video_output[0]['modelInput']['messages'][0]['content']\n",
    "        prompt_texts = [html.escape(c['text']).replace('\\\\n', '\\n')\n",
    "                        for c in user_content if 'text' in c]\n",
    "        if prompt_texts:\n",
    "            body_parts.append(\"\\n**Prompt:**\\n\\n\")\n",
    "            body_parts.append(\"<div style='margin-bottom: 1em; font-style: italic;'>\")\n",
    "            body_parts.append(\"<br>\".join(prompt_texts))\n",
    "            body_parts.append(\"</div>\")\n",
    "            body_parts.append(\"\\n\\n---\\n\")  # Horizontal rule after prompt\n",
    "\n",
    "\n",
    "    # Process each video entry\n",
    "    for entry in video_output:\n",
    "        # Extract video name from S3 URI\n",
    "        video_uri = entry['modelInput']['messages'][0]['content'][1]['video']['source']['s3Location']['uri']\n",
    "        video_name = video_uri.split('/')[-1]  # Get filename from URI\n",
    "        \n",
    "        # Add video name header\n",
    "        body_parts.append(f\"\\n## 📹 {video_name}\\n\")\n",
    "        \n",
    "        # Process assistant summary\n",
    "        assistant_content = entry['modelOutput']['output']['message']['content']\n",
    "        for content in assistant_content:\n",
    "            if 'text' in content:\n",
    "                processed = process_content_string(content['text'])\n",
    "                body_parts.append(processed)\n",
    "        \n",
    "        # Add separator between entries\n",
    "        body_parts.append(\"\\n\\n---\\n\")\n",
    "\n",
    "    # Final styling\n",
    "    styled_markdown = f\"\"\"\n",
    "<div style=\"border: 2px solid #FFC000; \n",
    "    padding: 10px; \n",
    "    border-radius: 5px; \n",
    "    max-width: 100%;\">\n",
    "{''.join(body_parts)}\n",
    "</div>\"\"\"\n",
    "    display(Markdown(styled_markdown))\n",
    "\n",
    "def process_content_string(text):\n",
    "    \"\"\"Format thinking/answer blocks\"\"\"\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    \n",
    "    answer_style = \"\"\"<div style=\"background-color: #e8f5e9; \n",
    "        border-left: 4px solid #43a047; \n",
    "        padding: 10px; \n",
    "        margin: 10px 0; \n",
    "        border-radius: 4px;\">\n",
    "        <strong style=\"color: #43a047;\">Summary</strong>\n",
    "        <div style=\"margin-top: 8px; white-space: pre-wrap;\">{}</div>\n",
    "    </div>\"\"\"\n",
    "    \n",
    "    # Convert <answer> tags to summary blocks\n",
    "    text = re.sub(r'<answer>(.*?)</answer>', \n",
    "                 lambda m: answer_style.format(m.group(1)), \n",
    "                 text, \n",
    "                 flags=re.DOTALL)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf3e23",
   "metadata": {},
   "source": [
    "## List videos in Amazon S3\n",
    "Use the helper function to find all MP4s under your source prefix in your Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6a0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:14:42,673 INFO Listing MP4s under s3://batchnovabucket/video/batch/source/academic_source/\n",
      "2025-04-29 13:14:42,757 INFO   • video/batch/source/academic_source/Charades/0AGCS.mp4\n",
      "2025-04-29 13:14:42,758 INFO   • video/batch/source/academic_source/Charades/0JJIY.mp4\n",
      "2025-04-29 13:14:42,759 INFO   • video/batch/source/academic_source/Charades/13AUQ.mp4\n",
      "2025-04-29 13:14:42,759 INFO   • video/batch/source/academic_source/Charades/13XM4.mp4\n",
      "2025-04-29 13:14:42,760 INFO   • video/batch/source/academic_source/Charades/2IX2Z.mp4\n",
      "2025-04-29 13:14:42,760 INFO   • video/batch/source/academic_source/Charades/2O5NR.mp4\n",
      "2025-04-29 13:14:42,761 INFO   • video/batch/source/academic_source/Charades/38I4G.mp4\n",
      "2025-04-29 13:14:42,762 INFO   • video/batch/source/academic_source/Charades/3RN5M.mp4\n",
      "2025-04-29 13:14:42,762 INFO   • video/batch/source/academic_source/Charades/45BIP.mp4\n",
      "2025-04-29 13:14:42,763 INFO   • video/batch/source/academic_source/Charades/51RLB.mp4\n",
      "2025-04-29 13:14:42,763 INFO   • video/batch/source/academic_source/Charades/5C4EK.mp4\n",
      "2025-04-29 13:14:42,764 INFO   • video/batch/source/academic_source/Charades/83S5W.mp4\n",
      "2025-04-29 13:14:42,764 INFO   • video/batch/source/academic_source/Charades/83XF0.mp4\n",
      "2025-04-29 13:14:42,770 INFO   • video/batch/source/academic_source/Charades/8Y7P5.mp4\n",
      "2025-04-29 13:14:42,771 INFO   • video/batch/source/academic_source/Charades/9207X.mp4\n",
      "2025-04-29 13:14:42,772 INFO   • video/batch/source/academic_source/Charades/ALXUC.mp4\n",
      "2025-04-29 13:14:42,773 INFO   • video/batch/source/academic_source/Charades/AVH53.mp4\n",
      "2025-04-29 13:14:42,774 INFO   • video/batch/source/academic_source/Charades/BLWIW.mp4\n",
      "2025-04-29 13:14:42,775 INFO   • video/batch/source/academic_source/Charades/CBG3N.mp4\n",
      "2025-04-29 13:14:42,776 INFO   • video/batch/source/academic_source/Charades/CX5ZM.mp4\n",
      "2025-04-29 13:14:42,776 INFO   • video/batch/source/academic_source/Charades/DD5SD.mp4\n",
      "2025-04-29 13:14:42,778 INFO   • video/batch/source/academic_source/Charades/DP1TV.mp4\n",
      "2025-04-29 13:14:42,780 INFO   • video/batch/source/academic_source/Charades/DZNYK.mp4\n",
      "2025-04-29 13:14:42,780 INFO   • video/batch/source/academic_source/Charades/F31X6.mp4\n",
      "2025-04-29 13:14:42,781 INFO   • video/batch/source/academic_source/Charades/FY9UT.mp4\n",
      "2025-04-29 13:14:42,782 INFO   • video/batch/source/academic_source/Charades/FYHTC.mp4\n",
      "2025-04-29 13:14:42,783 INFO   • video/batch/source/academic_source/Charades/GG4UR.mp4\n",
      "2025-04-29 13:14:42,784 INFO   • video/batch/source/academic_source/Charades/HQ8K2.mp4\n",
      "2025-04-29 13:14:42,785 INFO   • video/batch/source/academic_source/Charades/J53NS.mp4\n",
      "2025-04-29 13:14:42,786 INFO   • video/batch/source/academic_source/Charades/LZUAY.mp4\n",
      "2025-04-29 13:14:42,787 INFO   • video/batch/source/academic_source/Charades/M79TJ.mp4\n",
      "2025-04-29 13:14:42,788 INFO   • video/batch/source/academic_source/Charades/MGDO2.mp4\n",
      "2025-04-29 13:14:42,788 INFO   • video/batch/source/academic_source/Charades/MRSYL.mp4\n",
      "2025-04-29 13:14:42,789 INFO   • video/batch/source/academic_source/Charades/NYDRK.mp4\n",
      "2025-04-29 13:14:42,790 INFO   • video/batch/source/academic_source/Charades/P23HN.mp4\n",
      "2025-04-29 13:14:42,791 INFO   • video/batch/source/academic_source/Charades/P36YW.mp4\n",
      "2025-04-29 13:14:42,792 INFO   • video/batch/source/academic_source/Charades/PK2F0.mp4\n",
      "2025-04-29 13:14:42,793 INFO   • video/batch/source/academic_source/Charades/RIE30.mp4\n",
      "2025-04-29 13:14:42,794 INFO   • video/batch/source/academic_source/Charades/RTEO8.mp4\n",
      "2025-04-29 13:14:42,795 INFO   • video/batch/source/academic_source/Charades/RVV5Q.mp4\n",
      "2025-04-29 13:14:42,796 INFO   • video/batch/source/academic_source/Charades/TIY7F.mp4\n",
      "2025-04-29 13:14:42,797 INFO   • video/batch/source/academic_source/Charades/U8X15.mp4\n",
      "2025-04-29 13:14:42,799 INFO   • video/batch/source/academic_source/Charades/UE638.mp4\n",
      "2025-04-29 13:14:42,800 INFO   • video/batch/source/academic_source/Charades/V9JJL.mp4\n",
      "2025-04-29 13:14:42,800 INFO   • video/batch/source/academic_source/Charades/VKDLS.mp4\n",
      "2025-04-29 13:14:42,801 INFO   • video/batch/source/academic_source/Charades/WK5PL.mp4\n",
      "2025-04-29 13:14:42,802 INFO   • video/batch/source/academic_source/Charades/XF93D.mp4\n",
      "2025-04-29 13:14:42,802 INFO   • video/batch/source/academic_source/Charades/XP305.mp4\n",
      "2025-04-29 13:14:42,803 INFO   • video/batch/source/academic_source/Charades/Y1HOV.mp4\n",
      "2025-04-29 13:14:42,804 INFO   • video/batch/source/academic_source/Charades/Y91JG.mp4\n",
      "2025-04-29 13:14:42,805 INFO   • video/batch/source/academic_source/Charades/YLEEO.mp4\n",
      "2025-04-29 13:14:42,806 INFO   • video/batch/source/academic_source/NextQA/0001/4333253921.mp4\n",
      "2025-04-29 13:14:42,807 INFO   • video/batch/source/academic_source/NextQA/0015/4609514164.mp4\n",
      "2025-04-29 13:14:42,807 INFO   • video/batch/source/academic_source/NextQA/0018/3973097072.mp4\n",
      "2025-04-29 13:14:42,808 INFO   • video/batch/source/academic_source/NextQA/0034/5534387302.mp4\n",
      "2025-04-29 13:14:42,808 INFO   • video/batch/source/academic_source/NextQA/0063/11106167914.mp4\n",
      "2025-04-29 13:14:42,809 INFO   • video/batch/source/academic_source/NextQA/0097/3413667541.mp4\n",
      "2025-04-29 13:14:42,811 INFO   • video/batch/source/academic_source/NextQA/1000/4255049031.mp4\n",
      "2025-04-29 13:14:42,811 INFO   • video/batch/source/academic_source/NextQA/1001/2400900222.mp4\n",
      "2025-04-29 13:14:42,812 INFO   • video/batch/source/academic_source/NextQA/1001/6972796508.mp4\n",
      "2025-04-29 13:14:42,813 INFO   • video/batch/source/academic_source/NextQA/1005/7300856728.mp4\n",
      "2025-04-29 13:14:42,813 INFO   • video/batch/source/academic_source/NextQA/1005/9520717551.mp4\n",
      "2025-04-29 13:14:42,814 INFO   • video/batch/source/academic_source/NextQA/1007/3434972730.mp4\n",
      "2025-04-29 13:14:42,814 INFO   • video/batch/source/academic_source/NextQA/1008/3938939252.mp4\n",
      "2025-04-29 13:14:42,815 INFO   • video/batch/source/academic_source/NextQA/1010/12297528943.mp4\n",
      "2025-04-29 13:14:42,816 INFO   • video/batch/source/academic_source/NextQA/1014/4350795977.mp4\n",
      "2025-04-29 13:14:42,816 INFO   • video/batch/source/academic_source/NextQA/1015/5697824411.mp4\n",
      "2025-04-29 13:14:42,817 INFO   • video/batch/source/academic_source/NextQA/1018/6554011281.mp4\n",
      "2025-04-29 13:14:42,817 INFO   • video/batch/source/academic_source/NextQA/1026/6913450810.mp4\n",
      "2025-04-29 13:14:42,818 INFO   • video/batch/source/academic_source/NextQA/1026/9740013012.mp4\n",
      "2025-04-29 13:14:42,819 INFO   • video/batch/source/academic_source/NextQA/1051/10356090554.mp4\n",
      "2025-04-29 13:14:42,820 INFO   • video/batch/source/academic_source/NextQA/1051/4164771889.mp4\n",
      "2025-04-29 13:14:42,820 INFO   • video/batch/source/academic_source/NextQA/1052/8155669421.mp4\n",
      "2025-04-29 13:14:42,821 INFO   • video/batch/source/academic_source/NextQA/1101/6179595616.mp4\n",
      "2025-04-29 13:14:42,821 INFO   • video/batch/source/academic_source/NextQA/1124/3134451316.mp4\n",
      "2025-04-29 13:14:42,822 INFO   • video/batch/source/academic_source/NextQA/1124/5250826364.mp4\n",
      "2025-04-29 13:14:42,823 INFO   • video/batch/source/academic_source/NextQA/1161/10622567214.mp4\n",
      "2025-04-29 13:14:42,823 INFO   • video/batch/source/academic_source/NextQA/1161/5120998454.mp4\n",
      "2025-04-29 13:14:42,824 INFO   • video/batch/source/academic_source/NextQA/1161/9127813899.mp4\n",
      "2025-04-29 13:14:42,824 INFO   • video/batch/source/academic_source/NextQA/1162/7961460440.mp4\n",
      "2025-04-29 13:14:42,825 INFO   • video/batch/source/academic_source/NextQA/1164/7383417060.mp4\n",
      "2025-04-29 13:14:42,826 INFO   • video/batch/source/academic_source/activitynet/v1-3/train_val/v_JXazqQitVdQ.mp4\n",
      "2025-04-29 13:14:42,826 INFO   • video/batch/source/academic_source/activitynet/v1-3/train_val/v_k6AzbT12a9c.mp4\n",
      "2025-04-29 13:14:42,827 INFO   • video/batch/source/academic_source/activitynet/v_2RxbcK90TeA.mp4\n",
      "2025-04-29 13:14:42,827 INFO   • video/batch/source/academic_source/activitynet/v_3SLaaTD8t3Q.mp4\n",
      "2025-04-29 13:14:42,828 INFO   • video/batch/source/academic_source/activitynet/v_7lNAmkaMyyg.mp4\n",
      "2025-04-29 13:14:42,829 INFO   • video/batch/source/academic_source/activitynet/v_7wBrvMGZROQ.mp4\n",
      "2025-04-29 13:14:42,829 INFO   • video/batch/source/academic_source/activitynet/v_8tI9IsSpgeI.mp4\n",
      "2025-04-29 13:14:42,830 INFO   • video/batch/source/academic_source/activitynet/v_92kGXXfm6ok.mp4\n",
      "2025-04-29 13:14:42,831 INFO   • video/batch/source/academic_source/activitynet/v_9Zn0zErRckc.mp4\n",
      "2025-04-29 13:14:42,831 INFO   • video/batch/source/academic_source/activitynet/v_AOteP9srRpw.mp4\n",
      "2025-04-29 13:14:42,832 INFO   • video/batch/source/academic_source/activitynet/v_FCe1NVTbaZ4.mp4\n",
      "2025-04-29 13:14:42,832 INFO   • video/batch/source/academic_source/activitynet/v_IcfWEKjl_AY.mp4\n",
      "2025-04-29 13:14:42,834 INFO   • video/batch/source/academic_source/activitynet/v_NLkJgnrKaKM.mp4\n",
      "2025-04-29 13:14:42,835 INFO   • video/batch/source/academic_source/activitynet/v_V1SEaTS9hos.mp4\n",
      "2025-04-29 13:14:42,835 INFO   • video/batch/source/academic_source/activitynet/v_YZvdzvM-124.mp4\n",
      "2025-04-29 13:14:42,836 INFO   • video/batch/source/academic_source/activitynet/v_i2e67kStfk4.mp4\n",
      "2025-04-29 13:14:42,836 INFO   • video/batch/source/academic_source/activitynet/v_q8-iXvYyCGg.mp4\n",
      "2025-04-29 13:14:42,837 INFO   • video/batch/source/academic_source/activitynet/v_sGFbsMKkoYs.mp4\n",
      "2025-04-29 13:14:42,838 INFO   • video/batch/source/academic_source/activitynet/v_xmStXpxlG_I.mp4\n",
      "2025-04-29 13:14:42,838 INFO   • video/batch/source/academic_source/activitynet/v_yVsOoFr61x4.mp4\n",
      "2025-04-29 13:14:42,839 INFO   • video/batch/source/academic_source/youcook2/104/zO7LIiIMVgk/split_2.mp4\n",
      "2025-04-29 13:14:42,839 INFO   • video/batch/source/academic_source/youcook2/111/lSq6y2F35ig/split_2.mp4\n",
      "2025-04-29 13:14:42,842 INFO   • video/batch/source/academic_source/youcook2/116/TvKIeO1kmR4/split_0.mp4\n",
      "2025-04-29 13:14:42,843 INFO   • video/batch/source/academic_source/youcook2/202/pCTdsgv1wZ4/split_5.mp4\n",
      "2025-04-29 13:14:42,843 INFO   • video/batch/source/academic_source/youcook2/203/m7eR6vTPCxE/split_14.mp4\n",
      "2025-04-29 13:14:42,844 INFO   • video/batch/source/academic_source/youcook2/204/SRdsaqpnfd4/split_3.mp4\n",
      "2025-04-29 13:14:42,848 INFO   • video/batch/source/academic_source/youcook2/211/720an9dDfkY/split_0.mp4\n",
      "2025-04-29 13:14:42,849 INFO   • video/batch/source/academic_source/youcook2/221/FQRC8urWpew/split_2.mp4\n",
      "2025-04-29 13:14:42,850 INFO   • video/batch/source/academic_source/youcook2/221/UB1_MNpdvgs/split_6.mp4\n",
      "2025-04-29 13:14:42,851 INFO   • video/batch/source/academic_source/youcook2/221/v7U70gPylBA/split_11.mp4\n",
      "2025-04-29 13:14:42,851 INFO   • video/batch/source/academic_source/youcook2/226/Zoud8fEbWhE/split_5.mp4\n",
      "2025-04-29 13:14:42,852 INFO   • video/batch/source/academic_source/youcook2/226/iDMXdB88oQI/split_2.mp4\n",
      "2025-04-29 13:14:42,854 INFO   • video/batch/source/academic_source/youcook2/227/p8ZGmL-8w6E/split_0.mp4\n",
      "2025-04-29 13:14:42,860 INFO   • video/batch/source/academic_source/youcook2/227/xm5OTacqk0E/split_5.mp4\n",
      "2025-04-29 13:14:42,860 INFO   • video/batch/source/academic_source/youcook2/301/BFz-pqB2Opw/split_5.mp4\n",
      "2025-04-29 13:14:42,861 INFO   • video/batch/source/academic_source/youcook2/301/NK2xHVWojgY/split_0.mp4\n",
      "2025-04-29 13:14:42,862 INFO   • video/batch/source/academic_source/youcook2/307/GrCrG-EMr8g/split_6.mp4\n",
      "2025-04-29 13:14:42,863 INFO   • video/batch/source/academic_source/youcook2/309/gswKIbddBHw/split_6.mp4\n",
      "2025-04-29 13:14:42,863 INFO   • video/batch/source/academic_source/youcook2/323/lMNneVHjxk8/split_5.mp4\n",
      "2025-04-29 13:14:42,864 INFO   • video/batch/source/academic_source/youcook2/401/78dIqPhgnLs/split_6.mp4\n",
      "2025-04-29 13:14:42,864 INFO   • video/batch/source/academic_source/youcook2/401/awlqmed2nwU/split_5.mp4\n",
      "2025-04-29 13:14:42,865 INFO   • video/batch/source/academic_source/youcook2/401/awlqmed2nwU/split_6.mp4\n",
      "2025-04-29 13:14:42,865 INFO   • video/batch/source/academic_source/youcook2/401/f9mlIEtVt5s/split_1.mp4\n",
      "2025-04-29 13:14:42,866 INFO   • video/batch/source/academic_source/youcook2/406/9RRHAydI_xk/split_0.mp4\n",
      "2025-04-29 13:14:42,867 INFO   • video/batch/source/academic_source/youcook2/406/9RRHAydI_xk/split_1.mp4\n",
      "2025-04-29 13:14:42,867 INFO   • video/batch/source/academic_source/youcook2/409/Z6coaaI77PY/split_2.mp4\n",
      "2025-04-29 13:14:42,868 INFO   • video/batch/source/academic_source/youcook2/412/DBJUD9V-1rQ/split_6.mp4\n",
      "2025-04-29 13:14:42,868 INFO   • video/batch/source/academic_source/youcook2/412/KUL6f9Q5ER4/split_5.mp4\n",
      "2025-04-29 13:14:42,871 INFO   • video/batch/source/academic_source/youcook2/412/_HYoidFnb5w/split_3.mp4\n",
      "2025-04-29 13:14:42,871 INFO   • video/batch/source/academic_source/youcook2/425/Bts6MvK8f9k/split_5.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 videos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['video/batch/source/academic_source/Charades/0AGCS.mp4',\n",
       " 'video/batch/source/academic_source/Charades/0JJIY.mp4',\n",
       " 'video/batch/source/academic_source/Charades/13AUQ.mp4',\n",
       " 'video/batch/source/academic_source/Charades/13XM4.mp4',\n",
       " 'video/batch/source/academic_source/Charades/2IX2Z.mp4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_keys = list_mp4s_in_s3(BUCKET_NAME, VIDEOS_SOURCE_PREFIX)\n",
    "print(f\"Found {len(mp4_keys)} videos.\")\n",
    "mp4_keys[:5]  # show first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c754ae1",
   "metadata": {},
   "source": [
    "## Build JSONL Payload\n",
    "Convert the list of keys into a newline-delimited JSON file for batch input. This is the required format for the batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c05c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 131 records → video/batch/input/video_batch_1745932487.jsonl\n",
      "{\"recordId\": \"video-0\", \"modelInput\": {\"schemaVersion\": \"messages-v1\", \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": \"Please summarize this video in ~200 words.\"}, {\"video\": {\"format\": \"mp4\", \"source\": {\"s3Location\": {\"uri\": \"s3://batchnovabucket/video/batch/source/academic_source/Charades/0AGCS.mp4\"}}}}]}], \"inferenceConfig\": {\"maxTokens\": 200}}}\n",
      "{\"recordId\": \"video-1\", \"modelInput\": {\"schemaVersion\": \"messages-v1\", \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": \"Please summarize this  ...\n"
     ]
    }
   ],
   "source": [
    "records = build_jsonl_from_s3_keys(mp4_keys, BUCKET_NAME)\n",
    "input_key = f\"{INPUT_PREFIX}/video_batch_{int(time.time())}.jsonl\"\n",
    "jsonl_str = '\\n'.join(json.dumps(r) for r in records)\n",
    "print(f\"Generated {len(records)} records → {input_key}\")\n",
    "print(jsonl_str[:500], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252ae39",
   "metadata": {},
   "source": [
    "## Upload JSONL to S3\n",
    "Put the JSONL file into your input prefix for the batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d003008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded JSONL to s3://batchnovabucket/video/batch/input/video_batch_1745932487.jsonl\n"
     ]
    }
   ],
   "source": [
    "s3.put_object(Bucket=BUCKET_NAME, Key=input_key, Body=jsonl_str.encode('utf-8'))\n",
    "print(f\"Uploaded JSONL to s3://{BUCKET_NAME}/{input_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da294dc4",
   "metadata": {},
   "source": [
    "## Invoke Batch Inference Job\n",
    "Start the Nova Pro batch job. We point at the common `video/batch/` parent prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "411a9c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started job ARN: arn:aws:bedrock:us-east-1:058264445765:model-invocation-job/xuant7wnfdzt\n"
     ]
    }
   ],
   "source": [
    "resp = bedrock.create_model_invocation_job(\n",
    "    jobName=f\"batch-video-{int(time.time())}\",\n",
    "    modelId=MODEL_ID,\n",
    "    inputDataConfig={ 's3InputDataConfig': {\n",
    "        's3Uri': f\"s3://{BUCKET_NAME}/video/batch/\",\n",
    "        's3InputFormat': 'JSONL'\n",
    "    }},\n",
    "    outputDataConfig={ 's3OutputDataConfig': {\n",
    "        's3Uri': f\"s3://{BUCKET_NAME}/{OUTPUT_PREFIX}/\"\n",
    "    }},\n",
    "    roleArn=ROLE_ARN\n",
    ")\n",
    "job_arn = resp['jobArn']\n",
    "print(f\"Started job ARN: {job_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e30b6",
   "metadata": {},
   "source": [
    "## Poll Job Status\n",
    "Wait until the batch job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43f6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Submitted\n",
      "Status: Submitted\n",
      "Status: Submitted\n",
      "Status: Submitted\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Validating\n",
      "Status: Scheduled\n",
      "Status: Scheduled\n",
      "Status: Scheduled\n",
      "Status: Scheduled\n",
      "Status: Scheduled\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: Completed\n",
      "Final status: Completed\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status_resp = bedrock.get_model_invocation_job(jobIdentifier=job_arn)\n",
    "    status = status_resp['status']\n",
    "    print('Status:', status)\n",
    "    if status in ('Completed','Failed'):\n",
    "        break\n",
    "    time.sleep(10)\n",
    "print('Final status:', status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127afdf",
   "metadata": {},
   "source": [
    "## Download Results\n",
    "Fetch the generated JSONL output files to your local `./outputs/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e88e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded → outputs/video_batch_1745875178.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908166.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908205.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745875178.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745875178.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908166.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908205.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745931573.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745932487.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745875178.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908166.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908205.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745931573.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745932487.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745875178.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908166.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745908205.jsonl.out\n",
      "Downloaded → outputs/video_batch_1745931573.jsonl.out\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "out_uri = status_resp['outputDataConfig']['s3OutputDataConfig']['s3Uri']\n",
    "parsed = urlparse(out_uri)\n",
    "out_bucket, out_prefix = parsed.netloc, parsed.path.lstrip('/')\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "for page in paginator.paginate(Bucket=out_bucket, Prefix=out_prefix):\n",
    "    for obj in page.get('Contents', []):\n",
    "        if not obj['Key'].lower().endswith('.jsonl.out'):\n",
    "            continue\n",
    "        dst = os.path.join(OUTPUT_FOLDER, os.path.basename(obj['Key']))\n",
    "        s3.download_file(out_bucket, obj['Key'], dst)\n",
    "        print('Downloaded →', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99ed4f59-e9e8-4da8-82a6-a4ac1d9b6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract summaries from first output file after batch processing\n",
    "output_path = \"../batch/outputs\"\n",
    "output_files = os.listdir(output_path)\n",
    "objects = []\n",
    "with open(os.path.join(output_path, output_files[0]), 'r') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e71f9eb-e1d6-4e84-aaa9-d53357f2b42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"border: 2px solid #FFC000; \n",
       "    padding: 10px; \n",
       "    border-radius: 5px; \n",
       "    max-width: 100%;\">\n",
       "<div style='border: 2px solid #000000; \n",
       "            padding: 10px; \n",
       "            border-radius: 5px; \n",
       "            max-width: fit-content; \n",
       "            margin: 0 auto; \n",
       "            text-align: center; \n",
       "            font-weight: bold;'>Video summaries by batch processing with amazon.nova-pro-v1:0</div>\n",
       "\n",
       "**Prompt:**\n",
       "\n",
       "<div style='margin-bottom: 1em; font-style: italic;'>Please summarize this video in ~200 words.</div>\n",
       "\n",
       "---\n",
       "\n",
       "## 📹 0AGCS.mp4\n",
       "The video starts with a person standing in a room, holding a plaid blanket and looking down. The room has a white door, a wooden chair, and a red chair on the right side. There is a dog in the room, and a power outlet is mounted on the wall. The person then wraps the blanket around their body and continues to stand in the room. The person then proceeds to fold the blanket and places it on the wooden chair. The video ends with the person standing in the room, wearing a black jacket and gray pants.\n",
       "\n",
       "---\n",
       "\n",
       "## 📹 0JJIY.mp4\n",
       "The video begins with a view of a room with a desk, shelves, and various items. A woman enters the room and begins to arrange items on the desk. She picks up a plastic bag and a jug, and then pours the contents of the jug into the bag. She then puts the bag down and picks up a frame, examining it before placing it on the desk. The woman continues to arrange items on the desk, moving things around and organizing them.\n",
       "\n",
       "---\n",
       "\n",
       "## 📹 13AUQ.mp4\n",
       "Two boys are in the kitchen. One is standing at the counter and the other is standing next to him. The boy at the counter is eating something and the other boy is holding a plastic bag. There is a couch, a lamp, and a picture frame in the room.\n",
       "\n",
       "---\n",
       "\n",
       "## 📹 13XM4.mp4\n",
       "A man is walking into a room with a container of fruit. He takes out a fruit and pours juice into a cup. He then walks to the other side of the room and holds the cup while talking.\n",
       "\n",
       "---\n",
       "\n",
       "## 📹 2IX2Z.mp4\n",
       "The video depicts a man standing in a kitchen, holding a small object in his hand. He appears to be inspecting or examining the object closely. The kitchen is well-lit, and various kitchen items and appliances are visible in the background. The man's focus remains on the object throughout the video.\n",
       "\n",
       "---\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the first 5 summaries will be displayed\n",
    "first_five = objects[:5]\n",
    "model_name = MODEL_ID.rpartition('/')[-1]\n",
    "pretty_llm_print(first_five, title=\"Video summaries by batch processing with \" + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbdca7-2f3c-4eea-9aa7-454d5eabae09",
   "metadata": {},
   "source": [
    "### Integrating with Existing Workflows\n",
    "\n",
    "After retrieving the processed output data, you can integrate it into your existing workflows or analytics systems for further analysis or downstream processing. For example, you could:\n",
    "\n",
    "- Store the summarized videos in a database for easy access and querying.\n",
    "- Perform sentiment analysis or topic modeling on the summarized transcripts to gain additional insights.\n",
    "- Categorize the summarizes into actionable business buckets.\n",
    "\n",
    "The specific integration steps will depend on your existing workflows and systems, but the processed output data from the batch inference job can be easily incorporated into various data pipelines and analytics processes.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The notebook covers the entire process, from data preparation and formatting to job submission, output retrieval, and integration with existing workflows. You can leverage the JSONL outputs for further analysis or visualization. Feel free to adapt and extend this notebook to suit your specific requirements, and explore other use cases where batch inference can be applied to optimize your interactions with foundation models at scale. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
