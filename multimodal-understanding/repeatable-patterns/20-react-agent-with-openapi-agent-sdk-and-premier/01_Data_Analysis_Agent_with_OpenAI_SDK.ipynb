{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Report Generator using Amazon Bedrock Nova\n",
    "\n",
    "This notebook demonstrates using Amazon Nova Premier for data analysis through the OpenAI Agents SDK.\n",
    "\n",
    "This notebook assumes you are running the code with proper AWS credentials (preferably using an IAM role) and that you have enabled Amazon Bedrock models (in us-west-1) in your account. For more details on setting up temporary AWS credentials and enabling models, please refer to the provided documentation links.\n",
    "\n",
    "**Notes:**\n",
    "- Make sure you are running this code using your AWS Credentials. This notebook assumes you are loading the credentials using an IAM role, however, you may use your access_key if you are not using IAM Roles. For more details about how to set temporaty AWS credentials please check [this link](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html).\n",
    "- Before using Amazon Bedrock models in this notebook you need to enable them in your account in us-east-1, for more details about the steps required to enabled the model please check [this link](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html).\n",
    "- This notebook uses Amazon Nova Pro as default, all [charges on-demand on request basis](https://aws.amazon.com/bedrock/pricing/).\n",
    "- Amazon Nova Pro will be used with the [Cross-Region Inference mode](https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html).\n",
    "- While this notebook uses us-east-1, Amazon Nova is available in a variety of AWS Regions. Check our [document pages](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html) for more details about the regions available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required packages\n",
    "%pip install boto3 openai-agents -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.model_settings import ModelSettings\n",
    "from agents.tool import FunctionTool\n",
    "from typing import List, Dict, Optional, Any, Callable\n",
    "from pydantic import BaseModel, Field\n",
    "import functools\n",
    "import nest_asyncio\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# disabling tracing for better visibility\n",
    "set_tracing_disabled(disabled=True)\n",
    "# we will be running the agent in async\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model id\n",
    "model_id = \"litellm/bedrock/converse/us.amazon.nova-premier-v1:0\"\n",
    "\n",
    "# AWS region\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Function to convert OpenAI schema to Amazon Bedrock tool schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_openai_tool_to_bedrock_tool(tool: dict) -> FunctionTool:\n",
    "    \"\"\"\n",
    "    Converts an OpenAI tool to a Bedrock tool.\n",
    "    \"\"\"\n",
    "    return FunctionTool(\n",
    "        name=tool[\"name\"],\n",
    "        description=tool[\"description\"],\n",
    "        params_json_schema={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                k: v for k, v in tool[\"params_json_schema\"][\"properties\"].items()\n",
    "            },\n",
    "            \"required\": tool[\"params_json_schema\"].get(\"required\", []),\n",
    "        },\n",
    "        on_invoke_tool=tool[\"on_invoke_tool\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AnalysisInput(BaseModel):\n",
    "    dataset_name: str\n",
    "    row_count: int\n",
    "    column_names: List[str]\n",
    "    data_types: List[str]\n",
    "\n",
    "class AnalysisOutput(BaseModel):\n",
    "    summary: str\n",
    "    key_findings: List[str]\n",
    "\n",
    "class StatisticalAnalysisOutput(BaseModel):\n",
    "    column_stats: Dict[str, Dict[str, float]] = Field(..., description=\"Statistical metrics for each numeric column\")\n",
    "    correlations: List[Dict[str, Any]] = Field(..., description=\"Notable correlations between columns\")\n",
    "    data_quality_issues: List[str] = Field(..., description=\"Potential data quality concerns\")\n",
    "    recommendations: List[str] = Field(..., description=\"Recommended next analysis steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Analysis Tools\n",
    "Our agent will have access to two tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def analyze_data(input_data: AnalysisInput) -> AnalysisOutput:\n",
    "    \"\"\"Analyze the provided dataset information and generate basic insights\"\"\"\n",
    "    return AnalysisOutput(\n",
    "        summary=f\"Analysis of {input_data.dataset_name} with {input_data.row_count} rows\",\n",
    "        key_findings=[\n",
    "            f\"Dataset contains {len(input_data.column_names)} columns\",\n",
    "            \"Found mix of numeric and categorical variables\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@function_tool\n",
    "def statistical_analysis(input_data: AnalysisInput) -> StatisticalAnalysisOutput:\n",
    "    \"\"\"Perform advanced statistical analysis on the dataset including descriptive statistics, \n",
    "    correlation analysis, data quality assessment, and analysis recommendations\"\"\"\n",
    "    \n",
    "    # Simulated column statistics for numeric columns\n",
    "    column_stats = {}\n",
    "    for idx, (col, dtype) in enumerate(zip(input_data.column_names, input_data.data_types)):\n",
    "        if dtype == \"numeric\":\n",
    "            # Simulate some basic statistics for the column\n",
    "            column_stats[col] = {\n",
    "                \"mean\": 45.5 + idx * 10,\n",
    "                \"median\": 42.0 + idx * 8,\n",
    "                \"std\": 15.2 + idx * 2,\n",
    "                \"min\": 18.0 + idx,\n",
    "                \"max\": 65.0 + idx * 20,\n",
    "                \"missing_pct\": 0.5 + idx * 0.3\n",
    "            }\n",
    "    \n",
    "    # Simulated correlations\n",
    "    correlations = []\n",
    "    numeric_columns = [col for col, dtype in zip(input_data.column_names, input_data.data_types) \n",
    "                       if dtype == \"numeric\"]\n",
    "    \n",
    "    if len(numeric_columns) >= 2:\n",
    "        # Create some sample correlations between numeric columns\n",
    "        for i in range(len(numeric_columns) - 1):\n",
    "            correlations.append({\n",
    "                \"column1\": numeric_columns[i],\n",
    "                \"column2\": numeric_columns[i + 1],\n",
    "                \"correlation\": 0.7 - (i * 0.2),\n",
    "                \"strength\": \"strong\" if 0.7 - (i * 0.2) > 0.6 else \"moderate\"\n",
    "            })\n",
    "    \n",
    "    # Simulated data quality issues\n",
    "    data_quality_issues = [\n",
    "        f\"Found approximately {int(input_data.row_count * 0.02)} missing values across all columns\",\n",
    "        \"Potential outliers detected in numeric columns\"\n",
    "    ]\n",
    "    \n",
    "    # Recommendations based on data characteristics\n",
    "    recommendations = [\n",
    "        \"Consider imputing missing values before further analysis\",\n",
    "        \"Normalize numeric features for machine learning applications\"\n",
    "    ]\n",
    "    \n",
    "    if any(dtype == \"categorical\" for dtype in input_data.data_types):\n",
    "        recommendations.append(\"Use one-hot encoding for categorical variables\")\n",
    "    \n",
    "    # Add correlation-based recommendations\n",
    "    if correlations:\n",
    "        if any(corr[\"correlation\"] > 0.7 for corr in correlations):\n",
    "            recommendations.append(\"Consider feature selection to remove highly correlated variables\")\n",
    "    \n",
    "    return StatisticalAnalysisOutput(\n",
    "        column_stats=column_stats,\n",
    "        correlations=correlations,\n",
    "        data_quality_issues=data_quality_issues,\n",
    "        recommendations=recommendations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create agent\n",
    "analysis_agent = Agent(\n",
    "    name=\"Data Analysis Assistant\",\n",
    "    model=model_id,\n",
    "    model_settings=ModelSettings(temperature=0.1),\n",
    "    instructions=\"\"\"You are a data analysis assistant. You must always respond in markdown. For any dataset information provided:\n",
    "    1. Use analyze_data to generate basic insights\n",
    "    2. Use statistical_analysis to perform advanced statistics and gather key metrics\n",
    "    3. Combine results into a clear, comprehensive data analysis report\n",
    "    4. When appropriate, suggest what types of visualizations would be helpful for the data (but don't try to generate them)\n",
    "    5. Organize your findings in a structured, easy-to-read format\"\"\",\n",
    "    tools=[convert_openai_tool_to_bedrock_tool(analyze_data.__dict__), \n",
    "           convert_openai_tool_to_bedrock_tool(statistical_analysis.__dict__)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets add some sample data\n",
    "test_data = AnalysisInput(\n",
    "    dataset_name=\"employee_data\",\n",
    "    row_count=1000,\n",
    "    column_names=[\"age\", \"salary\", \"department\", \"years_experience\"],\n",
    "    data_types=[\"numeric\", \"numeric\", \"categorical\", \"numeric\"]\n",
    ")\n",
    "\n",
    "# Run analysis\n",
    "result = Runner.run_sync(\n",
    "    analysis_agent,\n",
    "    f\"Please analyze this dataset and provide statistical insights: {test_data.model_dump_json()}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<thinking>\n",
       "The user wants a comprehensive statistical analysis report. After running both tools:\n",
       "\n",
       "1. Basic analysis shows 4 columns with mixed data types and 1000 rows\n",
       "2. Statistical analysis provides:\n",
       "   - Descriptive stats for numeric columns (mean/median/std/range)\n",
       "   - Correlations between numeric variables (age-salary: strong, salary-experience: moderate)\n",
       "   - Data quality issues (missing values, potential outliers)\n",
       "   - Recommendations for preprocessing\n",
       "\n",
       "Now need to structure this into a markdown report with:\n",
       "- Dataset overview\n",
       "- Key metrics table\n",
       "- Correlation analysis\n",
       "- Data quality section\n",
       "- Visualization suggestions\n",
       "- Preprocessing recommendations\n",
       "\n",
       "Will verify calculations:\n",
       "- Years_experience mean=75.5 seems high (max=125?), might be typo but will report as given\n",
       "- Correlation values make sense (age-salary strong, salary-experience moderate)\n",
       "- Missing values: 0.5%+0.8%+1.4% = 2.7% → ~27 rows total\n",
       "\n",
       "Visualizations needed:\n",
       "- Histograms for numeric distributions\n",
       "- Boxplots for outlier detection\n",
       "- Scatter plots for correlations\n",
       "- Bar chart for department distribution\n",
       "</thinking>\n",
       "## **Employee Data Analysis Report**\n",
       "\n",
       "### **Dataset Overview**\n",
       "- **Name**: employee_data\n",
       "- **Rows**: 1,000\n",
       "- **Columns**: 4 (age, salary, department, years_experience)\n",
       "- **Data Types**: \n",
       "  - Numeric: age, salary, years_experience\n",
       "  - Categorical: department\n",
       "\n",
       "---\n",
       "\n",
       "### **Key Statistical Metrics**\n",
       "| Metric         | Age   | Salary | Years Experience |\n",
       "|----------------|-------|--------|------------------|\n",
       "| **Mean**       | 45.5  | 55.5   | 75.5             |\n",
       "| **Median**     | 42.0  | 50.0   | 66.0             |\n",
       "| **Std Dev**    | 15.2  | 17.2   | 21.2             |\n",
       "| **Min**        | 18    | 19     | 21               |\n",
       "| **Max**        | 65    | 85     | 125              |\n",
       "| **Missing %**  | 0.5%  | 0.8%   | 1.4%             |\n",
       "\n",
       "---\n",
       "\n",
       "### **Correlation Analysis**\n",
       "- **Strong Positive Correlation**:  \n",
       "  Age vs Salary (r=0.7)\n",
       "- **Moderate Positive Correlation**:  \n",
       "  Salary vs Years Experience (r=0.5)\n",
       "\n",
       "---\n",
       "\n",
       "### **Data Quality Observations**\n",
       "- **Missing Values**: ~20 total (2% of dataset)\n",
       "- **Potential Outliers**: Detected in numeric columns (requires validation)\n",
       "\n",
       "---\n",
       "\n",
       "### **Visualization Recommendations**\n",
       "1. **Histograms**:  \n",
       "   Distribution of age, salary, and years_experience\n",
       "2. **Boxplots**:  \n",
       "   Outlier detection in numeric variables\n",
       "3. **Scatter Plots**:  \n",
       "   Age vs Salary and Salary vs Experience\n",
       "4. **Bar Chart**:  \n",
       "   Department distribution\n",
       "\n",
       "---\n",
       "\n",
       "### **Preprocessing Recommendations**\n",
       "1. **Missing Values**: Impute using median/mean\n",
       "2. **Normalization**: Scale numeric features for modeling\n",
       "3. **Categorical Encoding**: One-hot encode \"department\"\n",
       "\n",
       "---\n",
       "\n",
       "### **Key Insights**\n",
       "- Salaries increase significantly with age (strong correlation)\n",
       "- Moderate relationship between experience and salary\n",
       "- Data quality issues require cleaning before analysis\n",
       "- Department distribution may impact salary/experience trends\n",
       "\n",
       "Would you like deeper analysis on any specific aspect?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the model output in markdown\n",
    "Markdown(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
