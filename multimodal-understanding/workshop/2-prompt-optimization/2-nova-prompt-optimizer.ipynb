{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83cd93c5",
   "metadata": {},
   "source": [
    "# (Optional Lab) Nova Prompt Optimizer\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Nova Prompt Optimizer is a powerful tool that automatically improves your prompts for Amazon Nova models using your own datasets. This workshop demonstrates how to:\n",
    "\n",
    "1. Transform manual prompt engineering into an efficient, data-driven process\n",
    "2. Optimize prompts specifically tailored to your use case and data\n",
    "3. Evaluate the performance improvements from optimization\n",
    "\n",
    "By the end of this notebook, you'll understand how to leverage automated prompt optimization to unlock the full potential of Amazon Nova models for your specific applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24872c14-366c-418f-8707-52347f7ad3e5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Optional Lab</b> \n",
    "    \n",
    "    This notebook takes 15 mins to run. Recommend to treat it as an optional notebook for AWS hosted event.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db810145",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Installation\n",
    "\n",
    "We'll start by installing the Nova Prompt Optimizer SDK, which provides the tools needed to automatically optimize prompts based on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5668aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:36:09.251412Z",
     "iopub.status.busy": "2025-07-25T19:36:09.251111Z",
     "iopub.status.idle": "2025-07-25T19:36:14.946902Z",
     "shell.execute_reply": "2025-07-25T19:36:14.945988Z",
     "shell.execute_reply.started": "2025-07-25T19:36:09.251389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nova-prompt-optimizer in /opt/conda/lib/python3.12/site-packages (1.0.52)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (3.1.6)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (1.37.1)\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (1.37.1)\n",
      "Requirement already satisfied: boto3-stubs in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (1.39.13)\n",
      "Requirement already satisfied: dspy in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (2.6.27)\n",
      "Collecting numpy==2.3.1 (from nova-prompt-optimizer)\n",
      "  Using cached numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: virtualenv==20.31.2 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (20.31.2)\n",
      "Requirement already satisfied: urllib3==2.5.0 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (2.5.0)\n",
      "Requirement already satisfied: setuptools==80.9.0 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (80.9.0)\n",
      "Requirement already satisfied: h11==0.16.0 in /opt/conda/lib/python3.12/site-packages (from nova-prompt-optimizer) (0.16.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.12/site-packages (from virtualenv==20.31.2->nova-prompt-optimizer) (0.3.9)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/conda/lib/python3.12/site-packages (from virtualenv==20.31.2->nova-prompt-optimizer) (3.18.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.12/site-packages (from virtualenv==20.31.2->nova-prompt-optimizer) (4.3.8)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3->nova-prompt-optimizer) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3->nova-prompt-optimizer) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore->nova-prompt-optimizer) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->nova-prompt-optimizer) (1.17.0)\n",
      "Requirement already satisfied: botocore-stubs in /opt/conda/lib/python3.12/site-packages (from boto3-stubs->nova-prompt-optimizer) (1.38.46)\n",
      "Requirement already satisfied: types-s3transfer in /opt/conda/lib/python3.12/site-packages (from boto3-stubs->nova-prompt-optimizer) (0.13.0)\n",
      "Requirement already satisfied: types-awscrt in /opt/conda/lib/python3.12/site-packages (from botocore-stubs->boto3-stubs->nova-prompt-optimizer) (0.27.4)\n",
      "Requirement already satisfied: backoff>=2.2 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (1.5.1)\n",
      "Requirement already satisfied: openai>=0.28.1 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (1.97.1)\n",
      "Requirement already satisfied: pandas>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (2.2.3)\n",
      "Requirement already satisfied: regex>=2023.10.3 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (2024.11.6)\n",
      "Requirement already satisfied: ujson>=5.8.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (5.10.0)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (4.0.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (2.32.4)\n",
      "Requirement already satisfied: optuna>=3.4.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (2.11.7)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (0.1.6)\n",
      "Requirement already satisfied: litellm>=1.60.3 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (1.74.8)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (0.48.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (9.1.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (3.1.1)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/conda/lib/python3.12/site-packages (from dspy->nova-prompt-optimizer) (13.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy->nova-prompt-optimizer) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy->nova-prompt-optimizer) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy->nova-prompt-optimizer) (4.14.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (19.0.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->dspy->nova-prompt-optimizer)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (0.33.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.14.6->dspy->nova-prompt-optimizer) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (1.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy->nova-prompt-optimizer) (1.1.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (8.2.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (6.10.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (1.1.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.12/site-packages (from litellm>=1.60.3->dspy->nova-prompt-optimizer) (0.21.4.dev0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->nova-prompt-optimizer) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (0.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy->nova-prompt-optimizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy->nova-prompt-optimizer) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy->nova-prompt-optimizer) (0.4.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (1.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy->nova-prompt-optimizer) (3.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai>=0.28.1->dspy->nova-prompt-optimizer) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from openai>=0.28.1->dspy->nova-prompt-optimizer) (0.10.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy->nova-prompt-optimizer) (1.16.2)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy->nova-prompt-optimizer) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy->nova-prompt-optimizer) (2.0.41)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy->nova-prompt-optimizer) (1.3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.1.1->dspy->nova-prompt-optimizer) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.1.1->dspy->nova-prompt-optimizer) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.31.0->dspy->nova-prompt-optimizer) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=13.7.1->dspy->nova-prompt-optimizer) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=13.7.1->dspy->nova-prompt-optimizer) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy->nova-prompt-optimizer) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy->nova-prompt-optimizer) (3.2.3)\n",
      "Using cached numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Installing collected packages: numpy, dill\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.2\n",
      "\u001b[2K    Uninstalling numpy-2.3.2:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.2━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: dill━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: dill None━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [dill]\u001b[1;31merror\u001b[0m: \u001b[1muninstall-no-record-file\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Cannot uninstall dill None\n",
      "\u001b[31m╰─>\u001b[0m The package's contents are unknown: no RECORD file was found for dill.\n",
      "\n",
      "\u001b[1;36mhint\u001b[0m: You might be able to recover from this via: \u001b[32mpip install --force-reinstall --no-deps dill==0.4.0\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [dill]\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nova-prompt-optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc38c9-7b03-4c7b-824c-dac92201aa15",
   "metadata": {},
   "source": [
    "## Section 2: Initialize the Input Adapters\n",
    "\n",
    "The Nova Prompt Optimizer uses adapters to standardize inputs from different sources. These adapters help connect your data, prompts, and evaluation metrics into the optimization pipeline.\n",
    "\n",
    "![adapters](nova_prompt_optimizer/docs/adapters.png)\n",
    "\n",
    "### 2.1 Dataset Adapter\n",
    "\n",
    "The Dataset Adapter converts your data into a standardized format for optimization and evaluation:\n",
    "\n",
    "- **Input Columns**: Specify which fields from your data will be used as inputs to the model\n",
    "- **Output Columns**: Specify which fields contain the expected outputs for comparison\n",
    "- **Train/Test Split**: Divide your dataset for optimization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da047488-0220-4e49-b8d0-361c5afcdfb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:36:14.948639Z",
     "iopub.status.busy": "2025-07-25T19:36:14.948286Z",
     "iopub.status.idle": "2025-07-25T19:36:14.959121Z",
     "shell.execute_reply": "2025-07-25T19:36:14.958381Z",
     "shell.execute_reply.started": "2025-07-25T19:36:14.948612Z"
    }
   },
   "outputs": [],
   "source": [
    "from amzn_nova_prompt_optimizer.core.input_adapters.dataset_adapter import JSONDatasetAdapter\n",
    "\n",
    "# Define which columns in our dataset contain inputs and expected outputs\n",
    "input_columns = {\"input\"}  # The field containing the user's query\n",
    "output_columns = {\"answer\"}  # The field containing the expected model response\n",
    "\n",
    "# Initialize the dataset adapter for our JSONL dataset\n",
    "dataset_adapter = JSONDatasetAdapter(input_columns, output_columns)\n",
    "\n",
    "# Load and process the dataset\n",
    "dataset_adapter.adapt(\"nova_prompt_optimizer/data/FacilitySupportAnalyzer.jsonl\")\n",
    "\n",
    "# Split into training data (for optimization) and test data (for evaluation)\n",
    "train_set, test_set = dataset_adapter.split(0.5)  # 50/50 split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22305416-5912-429f-b47b-04592a0966da",
   "metadata": {},
   "source": [
    "### 2.2 Prompt Adapter\n",
    "\n",
    "The Prompt Adapter standardizes your existing prompt template:\n",
    "\n",
    "- **Prompt Variables**: Identify placeholders in your prompt that should be replaced with data from input columns\n",
    "- **File Path**: Provide the path to your original prompt template\n",
    "- **Adapt**: Process the prompt into a standardized format for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "621dc01d-6896-4a37-ad64-63f27c597f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:36:14.961109Z",
     "iopub.status.busy": "2025-07-25T19:36:14.960398Z",
     "iopub.status.idle": "2025-07-25T19:36:14.968384Z",
     "shell.execute_reply": "2025-07-25T19:36:14.967682Z",
     "shell.execute_reply.started": "2025-07-25T19:36:14.960988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:36:14 INFO amzn_nova_prompt_optimizer.core.input_adapters.prompt_adapter: System Prompt not set, initializing as empty string...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<amzn_nova_prompt_optimizer.core.input_adapters.prompt_adapter.TextPromptAdapter at 0x7fa8b38168a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from amzn_nova_prompt_optimizer.core.input_adapters.prompt_adapter import TextPromptAdapter\n",
    "\n",
    "# Define which variables in our prompt will be replaced with data from input columns\n",
    "prompt_variables = input_columns\n",
    "\n",
    "# Initialize the prompt adapter for a text prompt file\n",
    "prompt_adapter = TextPromptAdapter()\n",
    "\n",
    "# Load the original prompt template and specify which variables to replace\n",
    "prompt_adapter.set_user_prompt(file_path=\"nova_prompt_optimizer/original_prompt/user_prompt_template.txt\", variables=prompt_variables)\n",
    "\n",
    "# Process the prompt into a standardized format\n",
    "prompt_adapter.adapt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349aeee-4f9a-49e0-94cb-029f2c4fb05f",
   "metadata": {},
   "source": [
    "### 2.3 Metric Adapter\n",
    "\n",
    "The Metric Adapter defines how to evaluate prompt performance:\n",
    "\n",
    "- **Custom Metrics**: Create evaluation metrics specific to your task\n",
    "- **Apply Function**: Evaluate a single model response against the expected output\n",
    "- **Batch Apply Function**: Evaluate multiple responses at once\n",
    "\n",
    "For this example, we'll create a custom metric for the Facility Support Analyzer task that measures:\n",
    "1. JSON validity\n",
    "2. Correctness of categories\n",
    "3. Accuracy of sentiment classification\n",
    "4. Accuracy of urgency classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f093a481-31a0-4871-99a0-670a60d67b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:01.578429Z",
     "iopub.status.busy": "2025-07-25T19:12:01.577634Z",
     "iopub.status.idle": "2025-07-25T19:12:01.598742Z",
     "shell.execute_reply": "2025-07-25T19:12:01.597484Z",
     "shell.execute_reply.started": "2025-07-25T19:12:01.578362Z"
    }
   },
   "outputs": [],
   "source": [
    "from amzn_nova_prompt_optimizer.core.input_adapters.metric_adapter import MetricAdapter\n",
    "from typing import List, Any, Dict\n",
    "import re\n",
    "import json\n",
    "\n",
    "class FacilitySupportAnalyzerMetric(MetricAdapter):\n",
    "    def parse_json(self, input_string: str):\n",
    "        \"\"\"\n",
    "        Attempts to parse the given string as JSON. If direct parsing fails,\n",
    "        it tries to extract a JSON snippet from code blocks formatted as:\n",
    "            ```json\n",
    "            ... JSON content ...\n",
    "            ```\n",
    "        or any code block delimited by triple backticks and then parses that content.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json.loads(input_string)\n",
    "        except json.JSONDecodeError as err:\n",
    "            error = err\n",
    "\n",
    "        patterns = [\n",
    "            re.compile(r\"```json\\s*(.*?)\\s*```\", re.DOTALL | re.IGNORECASE),\n",
    "            re.compile(r\"```(.*?)```\", re.DOTALL)\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = pattern.search(input_string)\n",
    "            if match:\n",
    "                json_candidate = match.group(1).strip()\n",
    "                try:\n",
    "                    return json.loads(json_candidate)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "        raise error\n",
    "\n",
    "    def _calculate_metrics(self, y_pred: Any, y_true: Any) -> Dict:\n",
    "        strict_json = False\n",
    "        result = {\n",
    "            \"is_valid_json\": False,\n",
    "            \"correct_categories\": 0.0,\n",
    "            \"correct_sentiment\": False,\n",
    "            \"correct_urgency\": False,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            y_true = y_true if isinstance(y_true, dict) else (json.loads(y_true) if strict_json else self.parse_json(y_true))\n",
    "            y_pred = y_pred if isinstance(y_pred, dict) else (json.loads(y_pred) if strict_json else self.parse_json(y_pred))\n",
    "        except json.JSONDecodeError:\n",
    "            result[\"total\"] = 0\n",
    "            return result  # Return result with is_valid_json = False\n",
    "        else:\n",
    "            result[\"is_valid_json\"] = True\n",
    "\n",
    "            categories_true = y_true.get(\"categories\", {})\n",
    "            categories_pred = y_pred.get(\"categories\", {})\n",
    "\n",
    "            if isinstance(categories_true, dict) and isinstance(categories_pred, dict):\n",
    "                correct = sum(\n",
    "                    categories_true.get(k, False) == categories_pred.get(k, False)\n",
    "                    for k in categories_true\n",
    "                )\n",
    "                result[\"correct_categories\"] = correct / len(categories_true) if categories_true else 0.0\n",
    "            else:\n",
    "                result[\"correct_categories\"] = 0.0  # or raise an error if you prefer\n",
    "\n",
    "            result[\"correct_sentiment\"] = y_pred.get(\"sentiment\", \"\") == y_true.get(\"sentiment\", \"\")\n",
    "            result[\"correct_urgency\"] = y_pred.get(\"urgency\", \"\") == y_true.get(\"urgency\", \"\")\n",
    "\n",
    "        # Compute overall metric score\n",
    "        result[\"total\"] = sum(\n",
    "            float(result[k]) for k in [\"correct_categories\", \"correct_sentiment\", \"correct_urgency\"]\n",
    "        ) / 3.0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def apply(self, y_pred: Any, y_true: Any):\n",
    "        return self._calculate_metrics(y_pred, y_true)\n",
    "\n",
    "    def batch_apply(self, y_preds: List[Any], y_trues: List[Any]):\n",
    "        evals = [self.apply(y_pred, y_true) for y_pred, y_true in zip(y_preds, y_trues)]\n",
    "        float_keys = [k for k, v in evals[0].items() if isinstance(v, (int, float, bool))]\n",
    "        return {k: sum(e[k] for e in evals) / len(evals) for k in float_keys}\n",
    "\n",
    "metric_adapter = FacilitySupportAnalyzerMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852c904-42e8-46a2-ad9e-a2e88d8eba6a",
   "metadata": {},
   "source": [
    "### 2.4 Inference Adapter\n",
    "\n",
    "The Inference Adapter connects to the model service:\n",
    "\n",
    "- **Backend**: Currently supports Amazon Bedrock\n",
    "- **Region**: Specify which AWS region to use for inference\n",
    "- **Configuration**: Set up the connection to the inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea654ddd-59d0-495e-8e56-29fe0ed6dd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:01.607930Z",
     "iopub.status.busy": "2025-07-25T19:12:01.606821Z",
     "iopub.status.idle": "2025-07-25T19:12:02.376388Z",
     "shell.execute_reply": "2025-07-25T19:12:02.375554Z",
     "shell.execute_reply.started": "2025-07-25T19:12:01.607897Z"
    }
   },
   "outputs": [],
   "source": [
    "from amzn_nova_prompt_optimizer.core.inference.adapter import BedrockInferenceAdapter\n",
    "\n",
    "# Initialize the inference adapter to connect to Amazon Bedrock\n",
    "# We're using us-west-2 region for this example\n",
    "inference_adapter = BedrockInferenceAdapter(region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb20883-793c-4b38-8e2c-7f2d461cc2fb",
   "metadata": {},
   "source": [
    "## Section 3: Evaluate the Original Prompt\n",
    "\n",
    "Before optimization, we'll establish a baseline by evaluating the original prompt's performance on our test dataset. This will help us measure the improvement from optimization.\n",
    "\n",
    "The Evaluator:\n",
    "- Takes our prompt, test data, metrics, and inference adapter\n",
    "- Generates predictions using the original prompt\n",
    "- Calculates evaluation metrics on these predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb5ac6",
   "metadata": {},
   "source": [
    "#### Base Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f158430-ed74-470c-8657-2b49b57ae79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:02.384988Z",
     "iopub.status.busy": "2025-07-25T19:12:02.384497Z",
     "iopub.status.idle": "2025-07-25T19:12:02.391811Z",
     "shell.execute_reply": "2025-07-25T19:12:02.390955Z",
     "shell.execute_reply.started": "2025-07-25T19:12:02.384939Z"
    }
   },
   "outputs": [],
   "source": [
    "from amzn_nova_prompt_optimizer.core.evaluation import Evaluator\n",
    "\n",
    "# Initialize the evaluator with all our components\n",
    "# - prompt_adapter: The prompt to evaluate\n",
    "# - test_set: Data to run the evaluation on\n",
    "# - metric_adapter: How to calculate performance metrics\n",
    "# - inference_adapter: Connection to the model service\n",
    "evaluator = Evaluator(prompt_adapter, test_set, metric_adapter, inference_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33974a07-c556-4238-a39c-12601fa01e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:02.394647Z",
     "iopub.status.busy": "2025-07-25T19:12:02.394263Z",
     "iopub.status.idle": "2025-07-25T19:12:41.743665Z",
     "shell.execute_reply": "2025-07-25T19:12:41.742790Z",
     "shell.execute_reply.started": "2025-07-25T19:12:02.394617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:12:02 INFO amzn_nova_prompt_optimizer.core.evaluation: Cache miss - Running new inference on Dataset\n",
      "Running inference: 100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "2025/07/25 19:12:41 INFO amzn_nova_prompt_optimizer.core.evaluation: Running Batch Evaluation on Dataset, using `batch_apply` metric\n",
      "2025/07/25 19:12:41 INFO amzn_nova_prompt_optimizer.core.evaluation: Using cached inference results\n",
      "2025/07/25 19:12:41 INFO amzn_nova_prompt_optimizer.core.evaluation: Running Evaluation on Dataset, using `apply` metric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt Evaluation Score = {'is_valid_json': 1.0, 'correct_categories': 0.888, 'correct_sentiment': 0.57, 'correct_urgency': 0.65, 'total': 0.7026666666666667}\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation of the original prompt with Amazon Nova Lite\n",
    "# This will generate predictions and calculate metrics\n",
    "original_prompt_score = evaluator.aggregate_score(model_id=\"us.amazon.nova-lite-v1:0\")\n",
    "\n",
    "print(f\"Original Prompt Evaluation Score = {original_prompt_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa60377",
   "metadata": {},
   "source": [
    "## Section 4: Optimize the Prompt\n",
    "\n",
    "Now we'll use the Nova Prompt Optimizer to automatically improve our prompt based on the training data.\n",
    "\n",
    "### 4.1 Optimization Metric\n",
    "\n",
    "First, we need to adapt our metric for the optimizer, which requires a single numerical score instead of multiple metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46adefe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:41.745833Z",
     "iopub.status.busy": "2025-07-25T19:12:41.745584Z",
     "iopub.status.idle": "2025-07-25T19:12:41.751325Z",
     "shell.execute_reply": "2025-07-25T19:12:41.749957Z",
     "shell.execute_reply.started": "2025-07-25T19:12:41.745812Z"
    }
   },
   "outputs": [],
   "source": [
    "class FacilitySupportAnalyzerNovaPromptOptimizerMetric(FacilitySupportAnalyzerMetric):\n",
    "    def apply(self, y_pred: Any, y_true: Any):\n",
    "        \"\"\"\n",
    "        Returns a single numerical value for the optimizer to use.\n",
    "        The optimizer needs a single score to maximize during optimization.\n",
    "        \n",
    "        Args:\n",
    "            y_pred: The model's prediction\n",
    "            y_true: The expected output\n",
    "            \n",
    "        Returns:\n",
    "            float: A score between 0 and 1, with higher being better\n",
    "        \"\"\"\n",
    "        # Calculate metrics and return the total score (average of all metrics)\n",
    "        return self._calculate_metrics(y_pred, y_true)[\"total\"]\n",
    "        \n",
    "    def batch_apply(self, y_preds: List[Any], y_trues: List[Any]):\n",
    "        # Not used during optimization\n",
    "        pass\n",
    "    \n",
    "# Create the metric adapter for optimization\n",
    "nova_prompt_optimizer_metric_adapter = FacilitySupportAnalyzerNovaPromptOptimizerMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab372d4-8ffc-4104-a5f6-30160a48f9f6",
   "metadata": {},
   "source": [
    "### 4.2 Optimization Adapters\n",
    "\n",
    "Next, we'll set up the optimization process. The Nova Prompt Optimizer takes:\n",
    "\n",
    "- **Prompt Adapter**: The original prompt to optimize\n",
    "- **Inference Adapter**: Connection to the model service\n",
    "- **Dataset Adapter**: Training data to learn from\n",
    "- **Metric Adapter**: How to evaluate prompt performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbc2fe-e95e-4cc0-9087-eaf0b111aa37",
   "metadata": {},
   "source": [
    "### 4.3 Nova Prompt Optimizer\n",
    "\n",
    "The Nova Prompt Optimizer uses a two-stage approach:\n",
    "\n",
    "1. **Meta Prompting**: Analyzes your prompt to identify system instructions and user template patterns\n",
    "2. **MIPROv2 Optimization**: Improves system instructions and adds few-shot examples based on your dataset\n",
    "\n",
    "The optimizer can run in different modes based on your Nova model:\n",
    "- **Lite mode**: Optimized for Nova Lite, faster optimization with fewer resources\n",
    "- **Pro mode**: Optimized for Nova Pro, more thorough optimization that may take longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c2d973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:12:41.752800Z",
     "iopub.status.busy": "2025-07-25T19:12:41.752455Z",
     "iopub.status.idle": "2025-07-25T19:25:57.451200Z",
     "shell.execute_reply": "2025-07-25T19:25:57.450356Z",
     "shell.execute_reply.started": "2025-07-25T19:12:41.752769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:12:44 INFO amzn_nova_prompt_optimizer.core.optimizers.nova_meta_prompter.nova_mp_optimizer: Optimizing prompt using Nova Meta Prompter with Model: us.amazon.nova-premier-v1:0\n",
      "2025/07/25 19:12:50 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Using us.amazon.nova-lite-v1:0 for Evaluation\n",
      "2025/07/25 19:12:50 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Using us.amazon.nova-premier-v1:0 for Prompting\n",
      "2025/07/25 19:12:50 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.custom_adapters.custom_chat_adapter: Initializing CustomChatAdapter with enable_json_fallback=False\n",
      "2025/07/25 19:12:50 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Using Nova tips for MIPROv2 optimization\n",
      "2025/07/25 19:12:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/07/25 19:12:50 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/07/25 19:12:50 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=20 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/20\n",
      "Bootstrapping set 2/20\n",
      "Bootstrapping set 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:01<?, ?it/s]\n",
      "2025/07/25 19:12:51 INFO dspy.teleprompt.mipro_optimizer_v2: Error generating few-shot examples: 'NoneType' object is not subscriptable\n",
      "2025/07/25 19:12:51 INFO dspy.teleprompt.mipro_optimizer_v2: Running without few-shot examples.\n",
      "2025/07/25 19:12:51 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Entering patched_propose_instructions, patching GroundedProposer with NovaGroundedProposer\n",
      "2025/07/25 19:12:51 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Patched GroundedProposer, current GroundedProposer class=<class 'amzn_nova_prompt_optimizer.core.optimizers.nova_prompt_optimizer.nova_grounded_proposer.NovaGroundedProposer'>\n",
      "2025/07/25 19:12:51 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/07/25 19:12:51 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2025/07/25 19:12:51 INFO amzn_nova_prompt_optimizer.core.optimizers.nova_prompt_optimizer.nova_grounded_proposer: Initializing NovaGroundedProposer\n",
      "2025/07/25 19:13:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=20 instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nova] Selected tip: structured_prompt\n",
      "[Nova] Selected tip: high_stakes\n",
      "[Nova] Selected tip: multi_turn\n",
      "[Nova] Selected tip: examples\n",
      "[Nova] Selected tip: rules_based\n",
      "[Nova] Selected tip: examples\n",
      "[Nova] Selected tip: none\n",
      "[Nova] Selected tip: simple\n",
      "[Nova] Selected tip: structured_prompt\n",
      "[Nova] Selected tip: format_control\n",
      "[Nova] Selected tip: description\n",
      "[Nova] Selected tip: simple\n",
      "[Nova] Selected tip: rules_based\n",
      "[Nova] Selected tip: format_control\n",
      "[Nova] Selected tip: creative\n",
      "[Nova] Selected tip: description\n",
      "[Nova] Selected tip: format_control\n",
      "[Nova] Selected tip: high_stakes\n",
      "[Nova] Selected tip: format_control\n",
      "[Nova] Selected tip: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 0: **Task:**\n",
      "Extract and return a JSON with specified keys and values based on the input.\n",
      "\n",
      "**Context:**\n",
      "- The JSON must include \"urgency\", \"sentiment\", and \"categories\".\n",
      "- \"urgency\" can be `high`, `medium`, or `low`.\n",
      "- \"sentiment\" can be `negative`, `neutral`, or `positive`.\n",
      "- \"categories\" is a dictionary with boolean values indicating if each category matches the input.\n",
      "\n",
      "**Instructions:**\n",
      "- MUST include all specified keys: \"urgency\", \"sentiment\", and \"categories\".\n",
      "- \"categories\" MUST include all listed support category tags with boolean values.\n",
      "- The JSON string MUST be valid and readable directly.\n",
      "- DO NOT enclose the JSON in ```json...```.\n",
      "- DO NOT include newlines or unnecessary whitespaces.\n",
      "\n",
      "**Response Format:**\n",
      "- The response MUST be a single-line JSON string.\n",
      "- MUST adhere to the specified format and include all required keys and values.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Given the critical nature of facility management service requests, accurately categorize the urgency, sentiment, and relevant categories of the following input. Ensure the JSON output is precise, valid, and includes all necessary keys (\"urgency\", \"sentiment\", and \"categories\" with boolean values for quality, safety, and urgent repairs). Incorrect categorization could lead to delays in service or improper handling of urgent issues.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with the keys \"urgency\" (values: \"high\", \"medium\", \"low\"), \"sentiment\" (values: \"negative\", \"neutral\", \"positive\"), and \"categories\" (a dictionary with keys \"quality\", \"safety\", \"urgent_repairs\" and boolean values). Ensure the JSON is valid, single-line, and includes all required keys without unnecessary whitespace.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 3: **\n",
      "Given a facility management service request, generate a JSON object with \"urgency\", \"sentiment\", and \"categories\" keys. Use the following guidelines:\n",
      "- \"urgency\" should be `high` for urgent repairs, `medium` for safety issues, and `low` for quality concerns.\n",
      "- \"sentiment\" should reflect the tone: `negative` for complaints, `neutral` for factual reports, and `positive` for polite requests.\n",
      "- \"categories\" must include `{\"quality\": bool, \"safety\": bool, \"urgent_repair\": bool}` with true/false values.\n",
      "\n",
      "**Examples:**\n",
      "- Valid: `{\"urgency\": \"high\", \"sentiment\": \"negative\", \"categories\": {\"quality\": false, \"safety\": false, \"urgent_repair\": true}}`\n",
      "- Invalid: `{\"urgency\": \"high\", \"categories\": {\"urgent_repair\": true}}` (missing sentiment and full categories)\n",
      "\n",
      "**Instructions:**\n",
      "- Ensure all keys are present and correctly formatted.\n",
      "- Base values on input content, not length.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given the input text, analyze the facility management service request to determine its urgency, sentiment, and relevant categories. Return a JSON string with the keys \"urgency\" (values: `high`, `medium`, `low`), \"sentiment\" (values: `negative`, `neutral`, `positive`), and \"categories\" (a dictionary with boolean values for \"quality\", \"safety\", and \"urgent repairs\"). Ensure compliance with data privacy standards and avoid any sensitive data exposure. The JSON must be valid, single-line, and formatted correctly without unnecessary whitespaces.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 5: **\n",
      "Given a facility management service request, generate a JSON object with \"urgency\", \"sentiment\", and \"categories\" keys. Use the following guidelines:\n",
      "- \"urgency\" should be `high` for urgent repairs, `medium` for safety issues, and `low` for quality concerns.\n",
      "- \"sentiment\" should reflect the tone: `negative` for complaints, `neutral` for standard requests, and `positive` for appreciative messages.\n",
      "- \"categories\" must include `quality`, `safety`, and `urgent_repair` with boolean values.\n",
      "\n",
      "**Examples:**\n",
      "- **Good:** `{\"urgency\":\"high\",\"sentiment\":\"negative\",\"categories\":{\"quality\":false,\"safety\":false,\"urgent_repair\":true}}`\n",
      "- **Bad:** `{\"urgency\":\"high\",\"categories\":{\"urgent_repair\":true}}` (Missing \"sentiment\" and incomplete \"categories\")\n",
      "\n",
      "**Instructions:**\n",
      "- Ensure all keys (\"urgency\", \"sentiment\", \"categories\") are present.\n",
      "- \"categories\" must cover all three tags with booleans.\n",
      "- Produce valid, compact JSON without formatting or extra spaces.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 6: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high, medium, low), \"sentiment\" (negative, neutral, positive), and \"categories\" (quality, safety, urgent_repairs as booleans). Ensure the JSON is valid, single-line, and contains all required keys without extra formatting.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 7: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high/medium/low), \"sentiment\" (negative/neutral/positive), and \"categories\" (quality, safety, urgent repairs as booleans). Ensure the JSON is valid and formatted correctly.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 8: **\n",
      "Given a facility management service request, generate a JSON object with \"urgency\", \"sentiment\", and \"categories\" keys.\n",
      "\n",
      "**Context:**\n",
      "- Analyze the input text for urgency (`high`, `medium`, `low`), sentiment (`negative`, `neutral`, `positive`), and relevant categories (quality, safety, urgent repairs).\n",
      "- The dataset shows polite, structured messages with urgency tied to sentiment.\n",
      "\n",
      "**Instructions:**\n",
      "- Return a JSON string with:\n",
      "  - \"urgency\": `\"high\"`, `\"medium\"`, or `\"low\"`\n",
      "  - \"sentiment\": `\"negative\"`, `\"neutral\"`, or `\"positive\"`\n",
      "  - \"categories\": `{\"quality\": bool, \"safety\": bool, \"urgent_repairs\": bool}`\n",
      "- Ensure valid JSON format without newlines or extra spaces.\n",
      "\n",
      "**Example:**\n",
      "Input: \"Immediate ceiling leak in Room 101. Very concerned about safety.\"\n",
      "Output: `{\"urgency\":\"high\",\"sentiment\":\"negative\",\"categories\":{\"quality\":false,\"safety\":true,\"urgent_repairs\":true}}`\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 9: Given a facility management service request, analyze the text and return a JSON object containing \"urgency\" (high/medium/low), \"sentiment\" (negative/neutral/positive), and \"categories\" (quality:bool, safety:bool, urgent_repairs:bool). Ensure the JSON is valid, single-line, and includes all keys with appropriate boolean values for categories based on the input text.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 10: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high, medium, low), \"sentiment\" (negative, neutral, positive), and \"categories\" (quality, safety, urgent repairs as booleans). Ensure the JSON is valid, concise, and includes all keys without unnecessary formatting.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 11: Given the input text, analyze it to determine the urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high/medium/low), \"sentiment\" (negative/neutral/positive), and \"categories\" (quality, safety, urgent repairs as booleans). Ensure the JSON is valid and concise.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 12: **\n",
      "Analyze the input text to extract relevant information and return a JSON object with \"urgency\", \"sentiment\", and \"categories\" keys. Ensure compliance with data privacy standards by not including any personal or sensitive information in the output.\n",
      "\n",
      "**Instructions:**\n",
      "- MUST classify \"urgency\" as `high`, `medium`, or `low` based on keywords and context.\n",
      "- MUST determine \"sentiment\" as `negative`, `neutral`, or `positive` using sentiment analysis.\n",
      "- MUST populate \"categories\" with boolean values for `quality`, `safety`, and `urgent_repairs`.\n",
      "- MUST ensure the JSON is valid, single-line, and contains no extra whitespace or newlines.\n",
      "\n",
      "**Compliance:**\n",
      "- Follow all relevant data protection regulations, ensuring no leakage of personal data.\n",
      "\n",
      "**Response Format:**\n",
      "- Return a JSON string like: `{\"urgency\": \"high\", \"sentiment\": \"negative\", \"categories\": {\"quality\": true, \"safety\": false, \"urgent_repairs\": true}}`\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 13: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with the following structure:\n",
      "```json\n",
      "{\"urgency\": \"high|medium|low\", \"sentiment\": \"negative|neutral|positive\", \"categories\": {\"quality\": true|false, \"safety\": true|false, \"urgent_repairs\": true|false}}\n",
      "```\n",
      "Ensure all keys are present, categories are evaluated as booleans, and the JSON is valid without formatting or whitespace.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 14: Given the input text, analyze and predict the urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high, medium, low), \"sentiment\" (negative, neutral, positive), and \"categories\" (quality, safety, urgent repairs as booleans). Ensure the JSON is concise, valid, and formatted as a single line without extraneous characters.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with the keys \"urgency\", \"sentiment\", and \"categories\". \"urgency\" should be one of `high`, `medium`, or `low`. \"sentiment\" should be `negative`, `neutral`, or `positive`. \"categories\" should include boolean values for \"quality\", \"safety\", and \"urgent repairs\". Ensure the JSON is valid, single-line, and includes all required keys with appropriate values.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 16: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with the keys \"urgency\" (values: \"high\", \"medium\", \"low\"), \"sentiment\" (values: \"negative\", \"neutral\", \"positive\"), and \"categories\" (a dictionary with keys \"quality\", \"safety\", \"urgent_repairs\" and boolean values). Ensure the JSON is valid, single-line, and contains no extra whitespace or newlines.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 17: Given the critical nature of facility management service requests, accurately categorize the urgency, sentiment, and relevant categories. Your output must be a precise JSON string with \"urgency\" (`high`, `medium`, `low`), \"sentiment\" (`negative`, `neutral`, `positive`), and \"categories\" (boolean values for quality, safety, urgent repairs). Ensure the JSON is valid, single-line, and includes all required keys without unnecessary formatting.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 18: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high/medium/low), \"sentiment\" (negative/neutral/positive), and \"categories\" (quality: true/false, safety: true/false, urgent_repairs: true/false). Ensure the JSON is valid, single-line, and contains no unnecessary characters or formatting.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: 19: Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with \"urgency\" (high, medium, low), \"sentiment\" (negative, neutral, positive), and \"categories\" (quality, safety, urgent_repairs as booleans). Ensure the JSON is valid, single-line, and includes all keys without unnecessary formatting.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:15:30 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.miprov2_optimizer: Restored GroundedProposer, current GroundedProposer class=<class 'dspy.propose.grounded_proposer.GroundedProposer'>\n",
      "2025/07/25 19:15:30 INFO amzn_nova_prompt_optimizer.core.optimizers.miprov2.custom_adapters.custom_chat_adapter: Initializing CustomChatAdapter with enable_json_fallback=False\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/07/25 19:15:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 37 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.63 / 50 (65.3%): 100%|██████████| 50/50 [00:26<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:15:57 INFO dspy.evaluate.evaluate: Average Metric: 32.63333333333333 / 50 (65.3%)\n",
      "2025/07/25 19:15:57 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 65.27\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/07/25 19:15:57 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.53 / 35 (64.4%): 100%|██████████| 35/35 [00:19<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:16:16 INFO dspy.evaluate.evaluate: Average Metric: 22.53333333333333 / 35 (64.4%)\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 64.38 on minibatch of size 35 with parameters ['Predictor 0: Instruction 12'].\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38]\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27]\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 65.27\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:16:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.03 / 35 (74.4%): 100%|██████████| 35/35 [00:20<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:16:36 INFO dspy.evaluate.evaluate: Average Metric: 26.03333333333333 / 35 (74.4%)\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.38 on minibatch of size 35 with parameters ['Predictor 0: Instruction 6'].\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38]\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27]\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 65.27\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:16:36 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.27 / 35 (69.3%): 100%|██████████| 35/35 [00:20<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:16:57 INFO dspy.evaluate.evaluate: Average Metric: 24.266666666666666 / 35 (69.3%)\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 69.33 on minibatch of size 35 with parameters ['Predictor 0: Instruction 8'].\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33]\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27]\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 65.27\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:16:57 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.17 / 35 (71.9%): 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:17:15 INFO dspy.evaluate.evaluate: Average Metric: 25.166666666666664 / 35 (71.9%)\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 71.9 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4'].\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9]\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27]\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 65.27\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:17:15 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.23 / 35 (72.1%): 100%|██████████| 35/35 [00:18<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:17:34 INFO dspy.evaluate.evaluate: Average Metric: 25.233333333333334 / 35 (72.1%)\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.1 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3'].\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1]\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27]\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 65.27\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:17:34 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 74.38) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.07 / 50 (74.1%): 100%|██████████| 50/50 [00:17<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:17:51 INFO dspy.evaluate.evaluate: Average Metric: 37.06666666666666 / 50 (74.1%)\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 74.13\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:17:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.53 / 35 (73.0%): 100%|██████████| 35/35 [00:19<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:18:10 INFO dspy.evaluate.evaluate: Average Metric: 25.53333333333333 / 35 (73.0%)\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.95 on minibatch of size 35 with parameters ['Predictor 0: Instruction 13'].\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95]\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:18:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.63 / 35 (70.4%): 100%|██████████| 35/35 [00:19<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:18:29 INFO dspy.evaluate.evaluate: Average Metric: 24.633333333333333 / 35 (70.4%)\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.38 on minibatch of size 35 with parameters ['Predictor 0: Instruction 9'].\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38]\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:18:29 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.27 / 35 (72.2%): 100%|██████████| 35/35 [00:20<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:18:50 INFO dspy.evaluate.evaluate: Average Metric: 25.266666666666666 / 35 (72.2%)\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.19 on minibatch of size 35 with parameters ['Predictor 0: Instruction 7'].\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19]\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:18:50 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.73 / 35 (73.5%): 100%|██████████| 35/35 [00:19<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:19:09 INFO dspy.evaluate.evaluate: Average Metric: 25.73333333333333 / 35 (73.5%)\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.52 on minibatch of size 35 with parameters ['Predictor 0: Instruction 18'].\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52]\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:19:09 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.77 / 35 (73.6%): 100%|██████████| 35/35 [00:11<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:19:21 INFO dspy.evaluate.evaluate: Average Metric: 25.766666666666666 / 35 (73.6%)\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.62 on minibatch of size 35 with parameters ['Predictor 0: Instruction 6'].\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62]\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13]\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:19:21 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 73.52) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.10 / 50 (72.2%): 100%|██████████| 50/50 [00:15<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:19:37 INFO dspy.evaluate.evaluate: Average Metric: 36.1 / 50 (72.2%)\n",
      "2025/07/25 19:19:37 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:19:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:19:37 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:19:37 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:19:37 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 14 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.80 / 35 (73.7%): 100%|██████████| 35/35 [00:09<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:19:46 INFO dspy.evaluate.evaluate: Average Metric: 25.8 / 35 (73.7%)\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 6'].\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71]\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:19:46 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 15 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.53 / 35 (73.0%): 100%|██████████| 35/35 [00:20<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:20:06 INFO dspy.evaluate.evaluate: Average Metric: 25.53333333333333 / 35 (73.0%)\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.95 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1'].\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95]\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:20:06 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 16 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.73 / 35 (73.5%): 100%|██████████| 35/35 [00:19<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:20:25 INFO dspy.evaluate.evaluate: Average Metric: 25.733333333333334 / 35 (73.5%)\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.52 on minibatch of size 35 with parameters ['Predictor 0: Instruction 10'].\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52]\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:20:25 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 17 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.17 / 35 (71.9%): 100%|██████████| 35/35 [00:20<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:20:45 INFO dspy.evaluate.evaluate: Average Metric: 25.166666666666664 / 35 (71.9%)\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 71.9 on minibatch of size 35 with parameters ['Predictor 0: Instruction 14'].\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9]\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:20:46 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 18 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.17 / 35 (74.8%): 100%|██████████| 35/35 [00:10<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:20:56 INFO dspy.evaluate.evaluate: Average Metric: 26.166666666666664 / 35 (74.8%)\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.76 on minibatch of size 35 with parameters ['Predictor 0: Instruction 6'].\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76]\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2]\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:20:56 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 73.52) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.57 / 50 (73.1%): 100%|██████████| 50/50 [00:22<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:21:18 INFO dspy.evaluate.evaluate: Average Metric: 36.56666666666666 / 50 (73.1%)\n",
      "2025/07/25 19:21:18 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:21:18 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:21:18 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:21:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:21:18 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 20 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.83 / 35 (68.1%): 100%|██████████| 35/35 [00:20<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:21:39 INFO dspy.evaluate.evaluate: Average Metric: 23.833333333333332 / 35 (68.1%)\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.1 on minibatch of size 35 with parameters ['Predictor 0: Instruction 17'].\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1]\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:21:39 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 21 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.60 / 35 (67.4%): 100%|██████████| 35/35 [00:19<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:21:59 INFO dspy.evaluate.evaluate: Average Metric: 23.599999999999998 / 35 (67.4%)\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2'].\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43]\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:21:59 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 22 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.67 / 35 (73.3%): 100%|██████████| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:22:13 INFO dspy.evaluate.evaluate: Average Metric: 25.666666666666664 / 35 (73.3%)\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 73.33 on minibatch of size 35 with parameters ['Predictor 0: Instruction 6'].\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33]\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:22:13 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 23 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.70 / 35 (70.6%): 100%|██████████| 35/35 [00:19<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:22:32 INFO dspy.evaluate.evaluate: Average Metric: 24.7 / 35 (70.6%)\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 70.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 16'].\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57]\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:22:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 24 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.03 / 35 (74.4%): 100%|██████████| 35/35 [00:18<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:22:51 INFO dspy.evaluate.evaluate: Average Metric: 26.03333333333333 / 35 (74.4%)\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.38 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38]\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13]\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 74.13\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:22:51 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 74.38) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.57 / 50 (75.1%): 100%|██████████| 50/50 [00:15<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:23:07 INFO dspy.evaluate.evaluate: Average Metric: 37.56666666666666 / 50 (75.1%)\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 75.13\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:23:07 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 26 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.73 / 35 (67.8%): 100%|██████████| 35/35 [00:18<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:23:26 INFO dspy.evaluate.evaluate: Average Metric: 23.73333333333333 / 35 (67.8%)\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 67.81 on minibatch of size 35 with parameters ['Predictor 0: Instruction 19'].\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81]\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:23:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 27 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.87 / 35 (76.8%): 100%|██████████| 35/35 [00:12<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:23:38 INFO dspy.evaluate.evaluate: Average Metric: 26.866666666666667 / 35 (76.8%)\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 76.76 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76]\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:23:38 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 28 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.47 / 35 (75.6%): 100%|██████████| 35/35 [00:06<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:23:45 INFO dspy.evaluate.evaluate: Average Metric: 26.466666666666665 / 35 (75.6%)\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.62 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62]\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:23:45 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 29 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.40 / 35 (75.4%): 100%|██████████| 35/35 [00:12<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:23:57 INFO dspy.evaluate.evaluate: Average Metric: 26.4 / 35 (75.4%)\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 75.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43]\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:23:57 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 30 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.30 / 35 (78.0%): 100%|██████████| 35/35 [00:12<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:24:10 INFO dspy.evaluate.evaluate: Average Metric: 27.3 / 35 (78.0%)\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 78.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0]\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13]\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 31 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:24:10 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 72.95) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.13 / 50 (74.3%): 100%|██████████| 50/50 [00:18<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:24:28 INFO dspy.evaluate.evaluate: Average Metric: 37.13333333333333 / 50 (74.3%)\n",
      "2025/07/25 19:24:28 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:24:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:24:28 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:24:28 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:24:28 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 32 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.07 / 35 (77.3%): 100%|██████████| 35/35 [00:09<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:24:38 INFO dspy.evaluate.evaluate: Average Metric: 27.066666666666666 / 35 (77.3%)\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.33 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0, 77.33]\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:24:38 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 33 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.63 / 35 (76.1%): 100%|██████████| 35/35 [00:09<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:24:47 INFO dspy.evaluate.evaluate: Average Metric: 26.633333333333333 / 35 (76.1%)\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 76.1 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0, 77.33, 76.1]\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:24:47 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 34 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.80 / 35 (76.6%): 100%|██████████| 35/35 [00:09<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:24:57 INFO dspy.evaluate.evaluate: Average Metric: 26.8 / 35 (76.6%)\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 76.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 15'].\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0, 77.33, 76.1, 76.57]\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:24:57 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 35 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.47 / 35 (72.8%): 100%|██████████| 35/35 [00:18<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:25:16 INFO dspy.evaluate.evaluate: Average Metric: 25.466666666666665 / 35 (72.8%)\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.76 on minibatch of size 35 with parameters ['Predictor 0: Instruction 11'].\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0, 77.33, 76.1, 76.57, 72.76]\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/25 19:25:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 36 / 37 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.40 / 35 (72.6%): 100%|██████████| 35/35 [00:19<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:25:35 INFO dspy.evaluate.evaluate: Average Metric: 25.4 / 35 (72.6%)\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 72.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5'].\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [64.38, 74.38, 69.33, 71.9, 72.1, 72.95, 70.38, 72.19, 73.52, 73.62, 73.71, 72.95, 73.52, 71.9, 74.76, 68.1, 67.43, 73.33, 70.57, 74.38, 67.81, 76.76, 75.62, 75.43, 78.0, 77.33, 76.1, 76.57, 72.76, 72.57]\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27]\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 37 / 37 - Full Evaluation =====\n",
      "2025/07/25 19:25:35 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 72.95) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.03 / 50 (72.1%): 100%|██████████| 50/50 [00:21<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:25:57 INFO dspy.evaluate.evaluate: Average Metric: 36.03333333333333 / 50 (72.1%)\n",
      "2025/07/25 19:25:57 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [65.27, 74.13, 72.2, 73.13, 75.13, 74.27, 72.07]\n",
      "2025/07/25 19:25:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 75.13\n",
      "2025/07/25 19:25:57 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/25 19:25:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/25 19:25:57 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 75.13!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from amzn_nova_prompt_optimizer.core.optimizers import NovaPromptOptimizer\n",
    "\n",
    "# Initialize the Nova Prompt Optimizer with our components\n",
    "nova_prompt_optimizer = NovaPromptOptimizer(\n",
    "    prompt_adapter=prompt_adapter,        # Original prompt to optimize\n",
    "    inference_adapter=inference_adapter,  # Connection to model service\n",
    "    dataset_adapter=train_set,            # Training data to learn from\n",
    "    metric_adapter=nova_prompt_optimizer_metric_adapter  # How to evaluate performance\n",
    ")\n",
    "\n",
    "# Run the optimization process in \"lite\" mode for Nova Lite\n",
    "# This will analyze the prompt, identify improvements, and generate few-shot examples\n",
    "optimized_prompt_adapter = nova_prompt_optimizer.optimize(mode=\"lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbfc1f",
   "metadata": {},
   "source": [
    "### 4.4 Examining the Optimized Prompt\n",
    "\n",
    "Let's examine what the optimizer has produced. First, the optimized system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826f76fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:25:57.452207Z",
     "iopub.status.busy": "2025-07-25T19:25:57.452007Z",
     "iopub.status.idle": "2025-07-25T19:25:57.457117Z",
     "shell.execute_reply": "2025-07-25T19:25:57.456019Z",
     "shell.execute_reply.started": "2025-07-25T19:25:57.452189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given a facility management service request, analyze the text to determine its urgency, sentiment, and relevant categories. Return a JSON object with the keys \"urgency\", \"sentiment\", and \"categories\". \"urgency\" should be one of `high`, `medium`, or `low`. \"sentiment\" should be `negative`, `neutral`, or `positive`. \"categories\" should include boolean values for \"quality\", \"safety\", and \"urgent repairs\". Ensure the JSON is valid, single-line, and includes all required keys with appropriate values.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_prompt_adapter.system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8c6b5",
   "metadata": {},
   "source": [
    "### 4.5 Optimized User Prompt\n",
    "\n",
    "Now let's look at the optimized user prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad2ac43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:25:57.458937Z",
     "iopub.status.busy": "2025-07-25T19:25:57.458509Z",
     "iopub.status.idle": "2025-07-25T19:25:57.464409Z",
     "shell.execute_reply": "2025-07-25T19:25:57.463792Z",
     "shell.execute_reply.started": "2025-07-25T19:25:57.458913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extract and return a json with the following keys and values from the input provided: [{{ input }}]\\n- \"urgency\" as one of `high`, `medium`, `low`\\n- \"sentiment\" as one of `negative`, `neutral`, `positive`\\n- \"categories\" as a dictionary with categories as keys and boolean values indicating if the category matches the input. Categories are: `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, `facility_management_issues`'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_prompt_adapter.user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44cf06",
   "metadata": {},
   "source": [
    "### 4.6 Saving the Optimized Prompt\n",
    "\n",
    "Let's save the optimized prompt for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6a6bce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:30:25.234063Z",
     "iopub.status.busy": "2025-07-25T19:30:25.233762Z",
     "iopub.status.idle": "2025-07-25T19:30:25.238465Z",
     "shell.execute_reply": "2025-07-25T19:30:25.237627Z",
     "shell.execute_reply.started": "2025-07-25T19:30:25.234041Z"
    }
   },
   "outputs": [],
   "source": [
    "optimized_prompt_adapter.save(\"nova_prompt_optimizer/optimized_prompt/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30a347",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate the Optimized Prompt\n",
    "\n",
    "Now let's measure the performance of our optimized prompt on the test dataset to see how much improvement we've gained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65493b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:30:27.518359Z",
     "iopub.status.busy": "2025-07-25T19:30:27.517650Z",
     "iopub.status.idle": "2025-07-25T19:30:27.522501Z",
     "shell.execute_reply": "2025-07-25T19:30:27.521661Z",
     "shell.execute_reply.started": "2025-07-25T19:30:27.518329Z"
    }
   },
   "outputs": [],
   "source": [
    "from amzn_nova_prompt_optimizer.core.evaluation import Evaluator\n",
    "\n",
    "# Create a new evaluator for the optimized prompt\n",
    "evaluator = Evaluator(\n",
    "    optimized_prompt_adapter,  # Now using the optimized prompt\n",
    "    test_set,                  # Same test data as before\n",
    "    metric_adapter,            # Same evaluation metrics\n",
    "    inference_adapter          # Same model service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43b528d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:30:28.801209Z",
     "iopub.status.busy": "2025-07-25T19:30:28.800162Z",
     "iopub.status.idle": "2025-07-25T19:31:08.417251Z",
     "shell.execute_reply": "2025-07-25T19:31:08.416315Z",
     "shell.execute_reply.started": "2025-07-25T19:30:28.801173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:30:28 INFO amzn_nova_prompt_optimizer.core.evaluation: Cache miss - Running new inference on Dataset\n",
      "Running inference: 100%|██████████| 100/100 [00:39<00:00,  2.53it/s]\n",
      "2025/07/25 19:31:08 INFO amzn_nova_prompt_optimizer.core.evaluation: Running Batch Evaluation on Dataset, using `batch_apply` metric\n",
      "2025/07/25 19:31:08 INFO amzn_nova_prompt_optimizer.core.evaluation: Using cached inference results\n",
      "2025/07/25 19:31:08 INFO amzn_nova_prompt_optimizer.core.evaluation: Running Evaluation on Dataset, using `apply` metric\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation of the optimized prompt with Amazon Nova Lite\n",
    "nova_prompt_optimizer_eval_score = evaluator.aggregate_score(model_id=\"us.amazon.nova-lite-v1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0bfbfaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:36:19.332607Z",
     "iopub.status.busy": "2025-07-25T19:36:19.332233Z",
     "iopub.status.idle": "2025-07-25T19:36:19.337394Z",
     "shell.execute_reply": "2025-07-25T19:36:19.336485Z",
     "shell.execute_reply.started": "2025-07-25T19:36:19.332582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Prompt Evaluation Score = {'is_valid_json': 1.0, 'correct_categories': 0.905, 'correct_sentiment': 0.55, 'correct_urgency': 0.91, 'total': 0.7883333333333333}\n",
      "Improvement: 0.0857 (12.19%)\n"
     ]
    }
   ],
   "source": [
    "# Print the score and compare it to the original prompt\n",
    "print(f\"Optimized Prompt Evaluation Score = {nova_prompt_optimizer_eval_score}\")\n",
    "print(f\"Improvement: {nova_prompt_optimizer_eval_score['total'] - original_prompt_score['total']:.4f} ({(nova_prompt_optimizer_eval_score['total'] - original_prompt_score['total']) / original_prompt_score['total'] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b345963-5516-49c8-9b7c-91eccbfe348c",
   "metadata": {},
   "source": [
    "### 5.1 Saving Evaluation Results\n",
    "\n",
    "Let's save the detailed evaluation results for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2acd687-d68d-4b09-8bd3-7ae88626c9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T19:36:26.715022Z",
     "iopub.status.busy": "2025-07-25T19:36:26.714665Z",
     "iopub.status.idle": "2025-07-25T19:36:26.724137Z",
     "shell.execute_reply": "2025-07-25T19:36:26.723461Z",
     "shell.execute_reply.started": "2025-07-25T19:36:26.714998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 19:36:26 INFO amzn_nova_prompt_optimizer.core.evaluation: Successfully saved evaluation results to nova_prompt_optimizer/evals/nova_lite/nova_prompt_optimizer_eval.jsonl\n"
     ]
    }
   ],
   "source": [
    "evaluator.save(\"nova_prompt_optimizer/evals/nova_lite/nova_prompt_optimizer_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7af64",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this workshop, we've explored how to use the Nova Prompt Optimizer to automatically improve prompt performance for Amazon Nova models. Let's summarize what we've learned and the benefits of this approach.\n",
    "\n",
    "## Key Learnings\n",
    "\n",
    "### 1. The Power of Automated Optimization\n",
    "- **Data-Driven Improvements**: Rather than manual trial-and-error, we used our own dataset to guide prompt optimization\n",
    "- **Systematic Approach**: The optimizer methodically analyzes and enhances prompts through meta-prompting and few-shot learning\n",
    "- **Measurable Results**: We quantitatively measured performance gains between original and optimized prompts\n",
    "\n",
    "### 2. Components of the Nova Prompt Optimizer\n",
    "- **Dataset Adapter**: Standardized our dataset for use in optimization and evaluation\n",
    "- **Prompt Adapter**: Processed our original prompt into a format suitable for optimization\n",
    "- **Metric Adapter**: Provided custom evaluation metrics specific to our task\n",
    "- **Inference Adapter**: Connected us to Amazon Nova models for testing\n",
    "- **Optimization Process**: Combined meta-prompting and MIPROv2 techniques\n",
    "\n",
    "### 3. Optimization Techniques Applied\n",
    "- **System Prompt Refinement**: Improved the system instructions for better task understanding\n",
    "- **Few-Shot Example Selection**: Automatically identified the most helpful examples from our data\n",
    "- **Format Optimization**: Enhanced output formatting and structure\n",
    "- **Task-Specific Guidance**: Added task-specific tips and clarifications\n",
    "\n",
    "## Benefits for Production Applications\n",
    "\n",
    "1. **Reduced Engineering Time**: Automates the time-consuming process of prompt engineering\n",
    "2. **Consistent Performance**: Creates reliable, tested prompts for production use\n",
    "3. **Adaptability**: Easily update optimized prompts as your data or requirements change\n",
    "4. **Model Flexibility**: Works with different Amazon Nova models (Micro, Lite, Pro)\n",
    "5. **Customization**: Optimizes for your specific data and task requirements\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "As you apply the [Nova Prompt Optimizer](https://github.com/aws/nova-prompt-optimizer) to your own projects, consider:\n",
    "\n",
    "1. **Expand Your Dataset**: Larger, more diverse datasets often yield better optimization results\n",
    "2. **Test Different Metrics**: Create custom metrics that align closely with your business goals\n",
    "3. **Compare Models**: Try optimizing for different Nova models to find the best performance/cost balance\n",
    "4. **Periodic Re-optimization**: Update your prompts as your data or requirements evolve\n",
    "5. **Integration**: Incorporate optimized prompts into your production applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
